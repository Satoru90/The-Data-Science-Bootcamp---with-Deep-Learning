{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cbf5f7c2",
   "metadata": {},
   "source": [
    "1 - Derin Ögrenmede Feature Engineerin'e gerek yok\n",
    "2 - Tensorflow kullaniyoruz, Keras - API kullaniyoruz\n",
    "3 - Tensor = Cok boyutlu Matrix; Flow = Akis; Google tarafindan gelistirildi, Rakip - Facebook PyTorch\n",
    "4 - GPU (Ekran Kartlari ile hesap yapmak daha hizli)(CPU'da degilde)\n",
    "5 - Derin Ögrenme insan beyninin ögrenme seklini kopyalar, insan beyni nasil ögrenirse yapay sinir aglari da öyle ögrenir\n",
    "6 - Nöronlar arasinda gidip gelme islemine epoch denir (Bir sokaktan 1000lerce gezince uzman oluyorsunuz)\n",
    "7 - Her nörondan digerine bir agirlik aktarilir (Katyasi) aktarili\n",
    "8 - Aktarma islemine Aktivasyon Functionu karar verir: ReLu, Softmax, Sigmoid\n",
    "9 - Resimler cok büyük oldugu icin parca parca islenir, buna da batch-size denir\n",
    "10 - Resimler üzerinde calisiyorsaniz CNN kullanilir.\n",
    "11 - Resim, Text, Video Üretme islemler LSTM ile yapilir. (Long-Short Time Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882cb51",
   "metadata": {},
   "source": [
    "### Deep Learning ile Makine Ögrenmesi\n",
    "* 1.Classification\n",
    "* 2.Regression\n",
    "* 3.Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870a2ef",
   "metadata": {},
   "source": [
    "## Deep Learning -  1. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be685c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61bf24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7c0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential #bir siraya koymaya saglicak\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9832780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af31af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4d6d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cbfc1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2135bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044a55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e624f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[[\"Outcome\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470ccf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8] # ilk 7 sutün aliyor\n",
    "y=df.iloc[:,8] # sadece 8. sutün al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba65e0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape # 8 sutün, yani birinci Layer 8 Nüron koyuyoruz, ikinciye istedigimiz kadar, 500,1000 vb.\n",
    "#aslinda row 1000den fazla olursa deep learning yoksa classic machine learning burasi sadece ögrenmek icin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c85974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aktivasyon Function\n",
    "#cevabi evet hayir - Sigmoid (genelde son da Sigmoid)\n",
    "# fazla ise - Softmix\n",
    "#Regression'da - Linear\n",
    "#bir den fazla Layer olursa - ReLu (aradaki Hidden Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5cbabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,activation='relu')) # Dense Layer eklemek = 1. Nüronun ikinci Layer'nin bütün nüronlarina baglanmasi\n",
    "model.add(Dense(12,activation='relu')) # nüron sayisi arttirma basari orani arttiriyor\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) # sonu 1 olmasi lazim ve classification oldugu icin sigmoid - output\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\", metrics=\"accuracy\") #binary= 0 veya 1, Adam=, metrics accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84d146e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 671us/step - loss: 1.3904 - accuracy: 0.4792\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.7341 - accuracy: 0.6302\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.6923 - accuracy: 0.6484\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 698us/step - loss: 0.6783 - accuracy: 0.6354\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 671us/step - loss: 0.6505 - accuracy: 0.6367\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 671us/step - loss: 0.6318 - accuracy: 0.6484\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.6253 - accuracy: 0.6615\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.6233 - accuracy: 0.6641\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.6239 - accuracy: 0.6784\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.6211 - accuracy: 0.6784\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6096 - accuracy: 0.6732\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.6166 - accuracy: 0.6732\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.6075 - accuracy: 0.6823\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.6043 - accuracy: 0.6862\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5953 - accuracy: 0.6823\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5875 - accuracy: 0.7005\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5796 - accuracy: 0.7135\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5859 - accuracy: 0.6927\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5801 - accuracy: 0.7031\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5750 - accuracy: 0.6940\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5757 - accuracy: 0.6966\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5820 - accuracy: 0.6966\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5831 - accuracy: 0.6901\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5755 - accuracy: 0.7070\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5734 - accuracy: 0.7135\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5776 - accuracy: 0.6966\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5673 - accuracy: 0.7109\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5668 - accuracy: 0.6953\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5685 - accuracy: 0.7057\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5716 - accuracy: 0.6914\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5604 - accuracy: 0.7122\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5602 - accuracy: 0.7227\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5668 - accuracy: 0.7135\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5625 - accuracy: 0.7161\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5579 - accuracy: 0.7174\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5774 - accuracy: 0.6992\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5623 - accuracy: 0.7188\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5536 - accuracy: 0.7279\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5492 - accuracy: 0.7214\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5560 - accuracy: 0.7188\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5551 - accuracy: 0.7344\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5538 - accuracy: 0.7201\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5522 - accuracy: 0.7227\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5517 - accuracy: 0.7318\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5583 - accuracy: 0.7174\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5476 - accuracy: 0.7188\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5479 - accuracy: 0.7318\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5480 - accuracy: 0.7357\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5457 - accuracy: 0.7279\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5499 - accuracy: 0.7305\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5512 - accuracy: 0.7240\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5419 - accuracy: 0.7318\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5485 - accuracy: 0.7188\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5490 - accuracy: 0.7318\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5450 - accuracy: 0.7292\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5394 - accuracy: 0.7370\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 671us/step - loss: 0.5418 - accuracy: 0.7305\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5381 - accuracy: 0.7357\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5435 - accuracy: 0.7305\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5430 - accuracy: 0.7383\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 698us/step - loss: 0.5418 - accuracy: 0.7279\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5352 - accuracy: 0.7409\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5372 - accuracy: 0.7240\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5396 - accuracy: 0.7370\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5339 - accuracy: 0.7227\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5327 - accuracy: 0.7357\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5340 - accuracy: 0.7344\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5345 - accuracy: 0.7331\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5318 - accuracy: 0.7396\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5333 - accuracy: 0.7370\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 658us/step - loss: 0.5328 - accuracy: 0.7292\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 658us/step - loss: 0.5251 - accuracy: 0.7513\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5331 - accuracy: 0.7370\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5290 - accuracy: 0.7409\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5261 - accuracy: 0.7422\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5244 - accuracy: 0.7526\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5250 - accuracy: 0.7552\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5331 - accuracy: 0.7461\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 655us/step - loss: 0.5268 - accuracy: 0.7448\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5228 - accuracy: 0.7435\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5230 - accuracy: 0.7344\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5239 - accuracy: 0.7565\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5269 - accuracy: 0.7396\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5263 - accuracy: 0.7513\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5253 - accuracy: 0.7461\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5233 - accuracy: 0.7422\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 645us/step - loss: 0.5282 - accuracy: 0.7552\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 658us/step - loss: 0.5229 - accuracy: 0.7409\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5218 - accuracy: 0.7552\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5154 - accuracy: 0.7552\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5178 - accuracy: 0.7526\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5237 - accuracy: 0.7357\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5116 - accuracy: 0.7643\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5121 - accuracy: 0.7552\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5123 - accuracy: 0.7487\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5138 - accuracy: 0.7435\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.5218 - accuracy: 0.7487\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5110 - accuracy: 0.7578\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5155 - accuracy: 0.7604\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5182 - accuracy: 0.7500\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5137 - accuracy: 0.7526\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5120 - accuracy: 0.7448\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5116 - accuracy: 0.7487\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5120 - accuracy: 0.7513\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5107 - accuracy: 0.7422\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5129 - accuracy: 0.7578\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5095 - accuracy: 0.7422\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5069 - accuracy: 0.7591\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5055 - accuracy: 0.7578\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5079 - accuracy: 0.7500\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5039 - accuracy: 0.7656\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5075 - accuracy: 0.7461\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5058 - accuracy: 0.7565\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5078 - accuracy: 0.7500\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.5048 - accuracy: 0.7604\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5028 - accuracy: 0.7552\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5038 - accuracy: 0.7578\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4985 - accuracy: 0.7630\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5035 - accuracy: 0.7461\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5023 - accuracy: 0.7630\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4979 - accuracy: 0.7526\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5123 - accuracy: 0.7474\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4943 - accuracy: 0.7708\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5009 - accuracy: 0.7552\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5047 - accuracy: 0.7513\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4970 - accuracy: 0.7734\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.4984 - accuracy: 0.7539\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.4967 - accuracy: 0.7630\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4997 - accuracy: 0.7669\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5046 - accuracy: 0.7630\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4972 - accuracy: 0.7656\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4945 - accuracy: 0.7474\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.4965 - accuracy: 0.7578\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4897 - accuracy: 0.7656\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.4853 - accuracy: 0.7630\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.4988 - accuracy: 0.7591\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4972 - accuracy: 0.7604\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4882 - accuracy: 0.7695\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.4876 - accuracy: 0.7708\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4907 - accuracy: 0.7565\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4915 - accuracy: 0.7591\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4977 - accuracy: 0.7448\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4858 - accuracy: 0.7578\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4905 - accuracy: 0.7643\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4854 - accuracy: 0.7669\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.4925 - accuracy: 0.7643\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.4851 - accuracy: 0.7734\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4865 - accuracy: 0.7643\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 632us/step - loss: 0.4965 - accuracy: 0.7552\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.4864 - accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x202cd5460a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=150,batch_size=10,verbose=1) \n",
    "# verbose asagdaki rakamlari gösteriyor, 0 da göstermiyor\n",
    "#batch-size: bir seferde 10 satir aliyor, verinin bir kismini aliyor isliyor sonra digerini aliyor, degirmen gibi ögütüyür, veriyi isliyor yeni veri aliyor bölük bölük\n",
    "#epoch= sokakta kac defa gidip geliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b53f1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237\n",
      "Trainable params: 237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c939f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 565us/step - loss: 0.4840 - accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6004398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48397183418273926"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0] # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c724f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708333134651184"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1] # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c76dc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping - 150 epoch güzel tahmin etmisiz ama gercekte 75 ideal mis, ozmn 75 de durmasi daha mantikli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dec0cd51",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "62/62 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7964 - val_loss: 0.5416 - val_accuracy: 0.7468\n",
      "Epoch 2/19\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.4457 - accuracy: 0.7736 - val_loss: 0.5487 - val_accuracy: 0.7597\n",
      "Epoch 3/19\n",
      "62/62 [==============================] - 0s 959us/step - loss: 0.4426 - accuracy: 0.7997 - val_loss: 0.5549 - val_accuracy: 0.7727\n",
      "Epoch 4/19\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.4342 - accuracy: 0.7866 - val_loss: 0.5582 - val_accuracy: 0.7403\n",
      "Epoch 5/19\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.4373 - accuracy: 0.7932 - val_loss: 0.5376 - val_accuracy: 0.7727\n",
      "Epoch 6/19\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.4353 - accuracy: 0.8046 - val_loss: 0.5550 - val_accuracy: 0.7403\n",
      "Epoch 7/19\n",
      "62/62 [==============================] - 0s 967us/step - loss: 0.4333 - accuracy: 0.7899 - val_loss: 0.5646 - val_accuracy: 0.7338\n",
      "Epoch 8/19\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.4365 - accuracy: 0.7883 - val_loss: 0.5539 - val_accuracy: 0.7532\n",
      "Epoch 9/19\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.5758 - val_accuracy: 0.7273\n",
      "Epoch 10/19\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.4448 - accuracy: 0.7818 - val_loss: 0.5667 - val_accuracy: 0.7338\n",
      "Epoch 11/19\n",
      "62/62 [==============================] - 0s 917us/step - loss: 0.4335 - accuracy: 0.7932 - val_loss: 0.5577 - val_accuracy: 0.7338\n",
      "Epoch 12/19\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.4326 - accuracy: 0.8013 - val_loss: 0.5336 - val_accuracy: 0.7597\n",
      "Epoch 13/19\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5915 - val_accuracy: 0.7078\n",
      "Epoch 14/19\n",
      "62/62 [==============================] - 0s 951us/step - loss: 0.4370 - accuracy: 0.8013 - val_loss: 0.5715 - val_accuracy: 0.7403\n",
      "Epoch 15/19\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.4488 - accuracy: 0.7883 - val_loss: 0.5847 - val_accuracy: 0.7143\n",
      "Epoch 16/19\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.4345 - accuracy: 0.7948 - val_loss: 0.5585 - val_accuracy: 0.7532\n",
      "Epoch 17/19\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.4378 - accuracy: 0.7866 - val_loss: 0.5669 - val_accuracy: 0.7468\n",
      "Epoch 18/19\n",
      "62/62 [==============================] - 0s 935us/step - loss: 0.4442 - accuracy: 0.7948 - val_loss: 0.5495 - val_accuracy: 0.7468\n",
      "Epoch 19/19\n",
      "62/62 [==============================] - 0s 918us/step - loss: 0.4412 - accuracy: 0.7915 - val_loss: 0.5567 - val_accuracy: 0.7338\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=19,validation_split=0.20,batch_size=10,verbose=1) \n",
    "# train test split yerine burda validation split -> test yerine validation kelimesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed529add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bae3a745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"ValAccuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d70b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression örnegi - pickel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5050eb",
   "metadata": {},
   "source": [
    "## Deep Learning - 2. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35ec2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7be2ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"kc_house.pkl\") # Datei mit Feature Engineering von vorher mit sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58092eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>price</th>\n",
       "      <th>zipcode_98002</th>\n",
       "      <th>zipcode_98003</th>\n",
       "      <th>zipcode_98004</th>\n",
       "      <th>zipcode_98005</th>\n",
       "      <th>zipcode_98006</th>\n",
       "      <th>zipcode_98007</th>\n",
       "      <th>zipcode_98008</th>\n",
       "      <th>zipcode_98010</th>\n",
       "      <th>zipcode_98011</th>\n",
       "      <th>zipcode_98014</th>\n",
       "      <th>zipcode_98019</th>\n",
       "      <th>zipcode_98022</th>\n",
       "      <th>zipcode_98023</th>\n",
       "      <th>zipcode_98024</th>\n",
       "      <th>zipcode_98027</th>\n",
       "      <th>zipcode_98028</th>\n",
       "      <th>zipcode_98029</th>\n",
       "      <th>zipcode_98030</th>\n",
       "      <th>zipcode_98031</th>\n",
       "      <th>zipcode_98032</th>\n",
       "      <th>zipcode_98033</th>\n",
       "      <th>zipcode_98034</th>\n",
       "      <th>zipcode_98038</th>\n",
       "      <th>zipcode_98039</th>\n",
       "      <th>zipcode_98040</th>\n",
       "      <th>zipcode_98042</th>\n",
       "      <th>zipcode_98045</th>\n",
       "      <th>zipcode_98052</th>\n",
       "      <th>zipcode_98053</th>\n",
       "      <th>zipcode_98055</th>\n",
       "      <th>zipcode_98056</th>\n",
       "      <th>zipcode_98058</th>\n",
       "      <th>zipcode_98059</th>\n",
       "      <th>zipcode_98065</th>\n",
       "      <th>zipcode_98070</th>\n",
       "      <th>zipcode_98072</th>\n",
       "      <th>zipcode_98074</th>\n",
       "      <th>zipcode_98075</th>\n",
       "      <th>zipcode_98077</th>\n",
       "      <th>zipcode_98092</th>\n",
       "      <th>zipcode_98102</th>\n",
       "      <th>zipcode_98103</th>\n",
       "      <th>zipcode_98105</th>\n",
       "      <th>zipcode_98106</th>\n",
       "      <th>zipcode_98107</th>\n",
       "      <th>zipcode_98108</th>\n",
       "      <th>zipcode_98109</th>\n",
       "      <th>zipcode_98112</th>\n",
       "      <th>zipcode_98115</th>\n",
       "      <th>zipcode_98116</th>\n",
       "      <th>zipcode_98117</th>\n",
       "      <th>zipcode_98118</th>\n",
       "      <th>zipcode_98119</th>\n",
       "      <th>zipcode_98122</th>\n",
       "      <th>zipcode_98125</th>\n",
       "      <th>zipcode_98126</th>\n",
       "      <th>zipcode_98133</th>\n",
       "      <th>zipcode_98136</th>\n",
       "      <th>zipcode_98144</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1180</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2170</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>770</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1050</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  condition  sqft_above     price  zipcode_98002  \\\n",
       "0     1.0   65          0          3        1180  221900.0              0   \n",
       "1     2.0   69          1          3        2170  538000.0              0   \n",
       "2     1.0   87          0          3         770  180000.0              0   \n",
       "3     1.0   55          0          5        1050  604000.0              0   \n",
       "4     1.0   33          0          3        1680  510000.0              0   \n",
       "\n",
       "   zipcode_98003  zipcode_98004  zipcode_98005  zipcode_98006  zipcode_98007  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98008  zipcode_98010  zipcode_98011  zipcode_98014  zipcode_98019  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98022  zipcode_98023  zipcode_98024  zipcode_98027  zipcode_98028  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              1   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98029  zipcode_98030  zipcode_98031  zipcode_98032  zipcode_98033  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98034  zipcode_98038  zipcode_98039  zipcode_98040  zipcode_98042  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98045  zipcode_98052  zipcode_98053  zipcode_98055  zipcode_98056  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98058  zipcode_98059  zipcode_98065  zipcode_98070  zipcode_98072  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98074  zipcode_98075  zipcode_98077  zipcode_98092  zipcode_98102  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   zipcode_98103  zipcode_98105  zipcode_98106  zipcode_98107  zipcode_98108  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98109  zipcode_98112  zipcode_98115  zipcode_98116  zipcode_98117  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98118  zipcode_98119  zipcode_98122  zipcode_98125  zipcode_98126  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98133  zipcode_98136  zipcode_98144  zipcode_98146  zipcode_98148  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              1              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  \\\n",
       "0              0              0              0              0              1   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76d6e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"price\",axis=1)\n",
    "y=df[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "810a6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "558fc243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "91b44f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0dac5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(19,activation='relu')) #Dense bütün nüronlar birbirne baglandi demek\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1)) # regression oldugu icin sigmoid yok\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\") #regression'da loss mse\n",
    "#regressionda büyükten baslayip kücüge gitmek usul dir\n",
    "#bastaki sutün sayisi sonra düsecek - regression icin örnek\n",
    "#nüronlari arttirmak basari arttirabilir, baska optimizer olabilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c371f268",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "119/119 [==============================] - 1s 2ms/step - loss: 267493965824.0000 - val_loss: 218579517440.0000\n",
      "Epoch 2/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 69888057344.0000 - val_loss: 33990010880.0000\n",
      "Epoch 3/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 33495398400.0000 - val_loss: 33655810048.0000\n",
      "Epoch 4/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 33074978816.0000 - val_loss: 33103226880.0000\n",
      "Epoch 5/1500\n",
      "119/119 [==============================] - 0s 911us/step - loss: 32432609280.0000 - val_loss: 32473255936.0000\n",
      "Epoch 6/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 31752597504.0000 - val_loss: 31899398144.0000\n",
      "Epoch 7/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 31150225408.0000 - val_loss: 31318484992.0000\n",
      "Epoch 8/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 30593871872.0000 - val_loss: 30796503040.0000\n",
      "Epoch 9/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 30138996736.0000 - val_loss: 30519449600.0000\n",
      "Epoch 10/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 29695240192.0000 - val_loss: 30087729152.0000\n",
      "Epoch 11/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 29389174784.0000 - val_loss: 29789640704.0000\n",
      "Epoch 12/1500\n",
      "119/119 [==============================] - 0s 920us/step - loss: 29146144768.0000 - val_loss: 29555963904.0000\n",
      "Epoch 13/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 28953882624.0000 - val_loss: 29577746432.0000\n",
      "Epoch 14/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 28876738560.0000 - val_loss: 29211942912.0000\n",
      "Epoch 15/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 28654540800.0000 - val_loss: 29077827584.0000\n",
      "Epoch 16/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 28540473344.0000 - val_loss: 28979204096.0000\n",
      "Epoch 17/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 28437112832.0000 - val_loss: 28899979264.0000\n",
      "Epoch 18/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 28343717888.0000 - val_loss: 28803966976.0000\n",
      "Epoch 19/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 28231923712.0000 - val_loss: 28740468736.0000\n",
      "Epoch 20/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 28168015872.0000 - val_loss: 28670121984.0000\n",
      "Epoch 21/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 28118274048.0000 - val_loss: 28648812544.0000\n",
      "Epoch 22/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 28062027776.0000 - val_loss: 28612902912.0000\n",
      "Epoch 23/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 28002955264.0000 - val_loss: 28529911808.0000\n",
      "Epoch 24/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 27980709888.0000 - val_loss: 28501370880.0000\n",
      "Epoch 25/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 27876503552.0000 - val_loss: 28424030208.0000\n",
      "Epoch 26/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 27831994368.0000 - val_loss: 28424548352.0000\n",
      "Epoch 27/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 27842238464.0000 - val_loss: 28386457600.0000\n",
      "Epoch 28/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 27732103168.0000 - val_loss: 28446214144.0000\n",
      "Epoch 29/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 27678861312.0000 - val_loss: 28456968192.0000\n",
      "Epoch 30/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 27693574144.0000 - val_loss: 28453150720.0000\n",
      "Epoch 31/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 27635800064.0000 - val_loss: 28310595584.0000\n",
      "Epoch 32/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 27544764416.0000 - val_loss: 28296577024.0000\n",
      "Epoch 33/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 27612954624.0000 - val_loss: 28141344768.0000\n",
      "Epoch 34/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 27491076096.0000 - val_loss: 28166211584.0000\n",
      "Epoch 35/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 27443963904.0000 - val_loss: 28037871616.0000\n",
      "Epoch 36/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 27412817920.0000 - val_loss: 27992268800.0000\n",
      "Epoch 37/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 27363014656.0000 - val_loss: 28073099264.0000\n",
      "Epoch 38/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 27381692416.0000 - val_loss: 27903522816.0000\n",
      "Epoch 39/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 27270268928.0000 - val_loss: 27937411072.0000\n",
      "Epoch 40/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 27241525248.0000 - val_loss: 27856713728.0000\n",
      "Epoch 41/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 27189637120.0000 - val_loss: 27785351168.0000\n",
      "Epoch 42/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 27206305792.0000 - val_loss: 27954839552.0000\n",
      "Epoch 43/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 27051483136.0000 - val_loss: 27656603648.0000\n",
      "Epoch 44/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 27005583360.0000 - val_loss: 27618762752.0000\n",
      "Epoch 45/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 26939375616.0000 - val_loss: 27601752064.0000\n",
      "Epoch 46/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 26880655360.0000 - val_loss: 27474518016.0000\n",
      "Epoch 47/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 26806876160.0000 - val_loss: 27406446592.0000\n",
      "Epoch 48/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 26743109632.0000 - val_loss: 27346968576.0000\n",
      "Epoch 49/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 26692616192.0000 - val_loss: 27424313344.0000\n",
      "Epoch 50/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 26659127296.0000 - val_loss: 27234152448.0000\n",
      "Epoch 51/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 26557859840.0000 - val_loss: 27095230464.0000\n",
      "Epoch 52/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 26406709248.0000 - val_loss: 27007713280.0000\n",
      "Epoch 53/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 26368778240.0000 - val_loss: 26913392640.0000\n",
      "Epoch 54/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 26254409728.0000 - val_loss: 27006087168.0000\n",
      "Epoch 55/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 26114172928.0000 - val_loss: 26711162880.0000\n",
      "Epoch 56/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 26032328704.0000 - val_loss: 26575714304.0000\n",
      "Epoch 57/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 25888413696.0000 - val_loss: 26665242624.0000\n",
      "Epoch 58/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 25711081472.0000 - val_loss: 26219948032.0000\n",
      "Epoch 59/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 25561651200.0000 - val_loss: 26064044032.0000\n",
      "Epoch 60/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 25314127872.0000 - val_loss: 25884301312.0000\n",
      "Epoch 61/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 25105680384.0000 - val_loss: 25726842880.0000\n",
      "Epoch 62/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 24830302208.0000 - val_loss: 25308854272.0000\n",
      "Epoch 63/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 24558563328.0000 - val_loss: 25331816448.0000\n",
      "Epoch 64/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 24214966272.0000 - val_loss: 24966754304.0000\n",
      "Epoch 65/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 23822927872.0000 - val_loss: 24290430976.0000\n",
      "Epoch 66/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 23356588032.0000 - val_loss: 23728609280.0000\n",
      "Epoch 67/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 22864693248.0000 - val_loss: 23144744960.0000\n",
      "Epoch 68/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 22476935168.0000 - val_loss: 22579908608.0000\n",
      "Epoch 69/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 21763332096.0000 - val_loss: 22116026368.0000\n",
      "Epoch 70/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 21158811648.0000 - val_loss: 21746366464.0000\n",
      "Epoch 71/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 20624379904.0000 - val_loss: 21215653888.0000\n",
      "Epoch 72/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 19930953728.0000 - val_loss: 20394704896.0000\n",
      "Epoch 73/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 19816427520.0000 - val_loss: 20441278464.0000\n",
      "Epoch 74/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 19251167232.0000 - val_loss: 19705053184.0000\n",
      "Epoch 75/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 18713139200.0000 - val_loss: 19499044864.0000\n",
      "Epoch 76/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 18523244544.0000 - val_loss: 19387850752.0000\n",
      "Epoch 77/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 18347376640.0000 - val_loss: 18819952640.0000\n",
      "Epoch 78/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 18012293120.0000 - val_loss: 19176943616.0000\n",
      "Epoch 79/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 17617068032.0000 - val_loss: 18546288640.0000\n",
      "Epoch 80/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 17355657216.0000 - val_loss: 17987430400.0000\n",
      "Epoch 81/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 16992777216.0000 - val_loss: 18019672064.0000\n",
      "Epoch 82/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 16924437504.0000 - val_loss: 17904670720.0000\n",
      "Epoch 83/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 16551530496.0000 - val_loss: 17311301632.0000\n",
      "Epoch 84/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 16108984320.0000 - val_loss: 17927354368.0000\n",
      "Epoch 85/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 15933020160.0000 - val_loss: 16673808384.0000\n",
      "Epoch 86/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 15616712704.0000 - val_loss: 16406587392.0000\n",
      "Epoch 87/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 15484254208.0000 - val_loss: 16227297280.0000\n",
      "Epoch 88/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 15254944768.0000 - val_loss: 15888849920.0000\n",
      "Epoch 89/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 14970092544.0000 - val_loss: 16027204608.0000\n",
      "Epoch 90/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 14776285184.0000 - val_loss: 15873974272.0000\n",
      "Epoch 91/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 14690793472.0000 - val_loss: 15253349376.0000\n",
      "Epoch 92/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 14306449408.0000 - val_loss: 15353882624.0000\n",
      "Epoch 93/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 14123287552.0000 - val_loss: 14882309120.0000\n",
      "Epoch 94/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 13860478976.0000 - val_loss: 14803903488.0000\n",
      "Epoch 95/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 13702226944.0000 - val_loss: 14859067392.0000\n",
      "Epoch 96/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 13921637376.0000 - val_loss: 15029484544.0000\n",
      "Epoch 97/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 13358214144.0000 - val_loss: 14555803648.0000\n",
      "Epoch 98/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 13114880000.0000 - val_loss: 14037790720.0000\n",
      "Epoch 99/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 13305883648.0000 - val_loss: 14104132608.0000\n",
      "Epoch 100/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 12898251776.0000 - val_loss: 13853665280.0000\n",
      "Epoch 101/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 12838788096.0000 - val_loss: 15433374720.0000\n",
      "Epoch 102/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 12680114176.0000 - val_loss: 13976585216.0000\n",
      "Epoch 103/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 12646118400.0000 - val_loss: 13503442944.0000\n",
      "Epoch 104/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 12479890432.0000 - val_loss: 13266880512.0000\n",
      "Epoch 105/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 12330727424.0000 - val_loss: 14040080384.0000\n",
      "Epoch 106/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 12301325312.0000 - val_loss: 13187684352.0000\n",
      "Epoch 107/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 12007395328.0000 - val_loss: 13363049472.0000\n",
      "Epoch 108/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 12023983104.0000 - val_loss: 13687149568.0000\n",
      "Epoch 109/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 11915168768.0000 - val_loss: 12724559872.0000\n",
      "Epoch 110/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 11858879488.0000 - val_loss: 12868236288.0000\n",
      "Epoch 111/1500\n",
      "119/119 [==============================] - 0s 916us/step - loss: 11966875648.0000 - val_loss: 12852180992.0000\n",
      "Epoch 112/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 11924284416.0000 - val_loss: 13300199424.0000\n",
      "Epoch 113/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 11659518976.0000 - val_loss: 12430334976.0000\n",
      "Epoch 114/1500\n",
      "119/119 [==============================] - 0s 992us/step - loss: 11522460672.0000 - val_loss: 12758333440.0000\n",
      "Epoch 115/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 11582598144.0000 - val_loss: 12503033856.0000\n",
      "Epoch 116/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 11451322368.0000 - val_loss: 12533431296.0000\n",
      "Epoch 117/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 11480438784.0000 - val_loss: 12380514304.0000\n",
      "Epoch 118/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 11560236032.0000 - val_loss: 12081597440.0000\n",
      "Epoch 119/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 11302337536.0000 - val_loss: 12223545344.0000\n",
      "Epoch 120/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 11166741504.0000 - val_loss: 12075042816.0000\n",
      "Epoch 121/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 11176408064.0000 - val_loss: 12228993024.0000\n",
      "Epoch 122/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 11073803264.0000 - val_loss: 12753697792.0000\n",
      "Epoch 123/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 11108779008.0000 - val_loss: 11849631744.0000\n",
      "Epoch 124/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 11120906240.0000 - val_loss: 12933073920.0000\n",
      "Epoch 125/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 11151051776.0000 - val_loss: 11771392000.0000\n",
      "Epoch 126/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 11030942720.0000 - val_loss: 11657617408.0000\n",
      "Epoch 127/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 10953372672.0000 - val_loss: 11705916416.0000\n",
      "Epoch 128/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 10881745920.0000 - val_loss: 12199858176.0000\n",
      "Epoch 129/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 10815759360.0000 - val_loss: 11546508288.0000\n",
      "Epoch 130/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10729869312.0000 - val_loss: 11490609152.0000\n",
      "Epoch 131/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 899us/step - loss: 10803812352.0000 - val_loss: 11683528704.0000\n",
      "Epoch 132/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 10653323264.0000 - val_loss: 11843921920.0000\n",
      "Epoch 133/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 10798589952.0000 - val_loss: 11399226368.0000\n",
      "Epoch 134/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 10775851008.0000 - val_loss: 11502490624.0000\n",
      "Epoch 135/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10785239040.0000 - val_loss: 11511454720.0000\n",
      "Epoch 136/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 10559508480.0000 - val_loss: 11488752640.0000\n",
      "Epoch 137/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 10484424704.0000 - val_loss: 11259029504.0000\n",
      "Epoch 138/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 10586207232.0000 - val_loss: 11268918272.0000\n",
      "Epoch 139/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 10564092928.0000 - val_loss: 11195375616.0000\n",
      "Epoch 140/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 10373163008.0000 - val_loss: 11152130048.0000\n",
      "Epoch 141/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 10480987136.0000 - val_loss: 11520882688.0000\n",
      "Epoch 142/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 10605574144.0000 - val_loss: 11103414272.0000\n",
      "Epoch 143/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 10550304768.0000 - val_loss: 11071993856.0000\n",
      "Epoch 144/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 10366454784.0000 - val_loss: 11091278848.0000\n",
      "Epoch 145/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 10373882880.0000 - val_loss: 11211554816.0000\n",
      "Epoch 146/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10364077056.0000 - val_loss: 11182090240.0000\n",
      "Epoch 147/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 10241484800.0000 - val_loss: 10970102784.0000\n",
      "Epoch 148/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 10310795264.0000 - val_loss: 10972649472.0000\n",
      "Epoch 149/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 10199342080.0000 - val_loss: 10898093056.0000\n",
      "Epoch 150/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 10331879424.0000 - val_loss: 11356596224.0000\n",
      "Epoch 151/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 10307501056.0000 - val_loss: 10915990528.0000\n",
      "Epoch 152/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 10285189120.0000 - val_loss: 11091977216.0000\n",
      "Epoch 153/1500\n",
      "119/119 [==============================] - 0s 906us/step - loss: 10168968192.0000 - val_loss: 10869071872.0000\n",
      "Epoch 154/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 10129011712.0000 - val_loss: 10960726016.0000\n",
      "Epoch 155/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10080805888.0000 - val_loss: 10799676416.0000\n",
      "Epoch 156/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10164927488.0000 - val_loss: 11296062464.0000\n",
      "Epoch 157/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 10012891136.0000 - val_loss: 10776203264.0000\n",
      "Epoch 158/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 10094493696.0000 - val_loss: 11235264512.0000\n",
      "Epoch 159/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 10004884480.0000 - val_loss: 10727994368.0000\n",
      "Epoch 160/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 10039527424.0000 - val_loss: 11457413120.0000\n",
      "Epoch 161/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10135618560.0000 - val_loss: 10777513984.0000\n",
      "Epoch 162/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 10249729024.0000 - val_loss: 10608154624.0000\n",
      "Epoch 163/1500\n",
      "119/119 [==============================] - 0s 975us/step - loss: 10009066496.0000 - val_loss: 11646318592.0000\n",
      "Epoch 164/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 10153469952.0000 - val_loss: 10846203904.0000\n",
      "Epoch 165/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10102851584.0000 - val_loss: 11697744896.0000\n",
      "Epoch 166/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9932276736.0000 - val_loss: 11078982656.0000\n",
      "Epoch 167/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9944503296.0000 - val_loss: 10524483584.0000\n",
      "Epoch 168/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9905004544.0000 - val_loss: 10487586816.0000\n",
      "Epoch 169/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9829908480.0000 - val_loss: 10469264384.0000\n",
      "Epoch 170/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9845935104.0000 - val_loss: 10454151168.0000\n",
      "Epoch 171/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 10102185984.0000 - val_loss: 11904745472.0000\n",
      "Epoch 172/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 9830587392.0000 - val_loss: 10713946112.0000\n",
      "Epoch 173/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9824654336.0000 - val_loss: 10866058240.0000\n",
      "Epoch 174/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9782333440.0000 - val_loss: 10536015872.0000\n",
      "Epoch 175/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 9819423744.0000 - val_loss: 10390921216.0000\n",
      "Epoch 176/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9803801600.0000 - val_loss: 10714635264.0000\n",
      "Epoch 177/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9911831552.0000 - val_loss: 10389521408.0000\n",
      "Epoch 178/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9640095744.0000 - val_loss: 10454803456.0000\n",
      "Epoch 179/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9658786816.0000 - val_loss: 10592595968.0000\n",
      "Epoch 180/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 10046914560.0000 - val_loss: 10479703040.0000\n",
      "Epoch 181/1500\n",
      "119/119 [==============================] - 0s 987us/step - loss: 9801383936.0000 - val_loss: 10270638080.0000\n",
      "Epoch 182/1500\n",
      "119/119 [==============================] - 0s 995us/step - loss: 9645446144.0000 - val_loss: 10295801856.0000\n",
      "Epoch 183/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9686204416.0000 - val_loss: 10449644544.0000\n",
      "Epoch 184/1500\n",
      "119/119 [==============================] - 0s 905us/step - loss: 9668496384.0000 - val_loss: 10246759424.0000\n",
      "Epoch 185/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9784760320.0000 - val_loss: 10352302080.0000\n",
      "Epoch 186/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9539001344.0000 - val_loss: 10349616128.0000\n",
      "Epoch 187/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9656474624.0000 - val_loss: 11384311808.0000\n",
      "Epoch 188/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9837272064.0000 - val_loss: 10168572928.0000\n",
      "Epoch 189/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9796434944.0000 - val_loss: 10176886784.0000\n",
      "Epoch 190/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9647687680.0000 - val_loss: 10133826560.0000\n",
      "Epoch 191/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9498158080.0000 - val_loss: 10262407168.0000\n",
      "Epoch 192/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9587328000.0000 - val_loss: 10111322112.0000\n",
      "Epoch 193/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9481542656.0000 - val_loss: 10098128896.0000\n",
      "Epoch 194/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9986867200.0000 - val_loss: 10494912512.0000\n",
      "Epoch 195/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 9668534272.0000 - val_loss: 10087813120.0000\n",
      "Epoch 196/1500\n",
      "119/119 [==============================] - 0s 902us/step - loss: 9450590208.0000 - val_loss: 10057551872.0000\n",
      "Epoch 197/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 9535960064.0000 - val_loss: 11388132352.0000\n",
      "Epoch 198/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9563171840.0000 - val_loss: 10335450112.0000\n",
      "Epoch 199/1500\n",
      "119/119 [==============================] - 0s 906us/step - loss: 9581903872.0000 - val_loss: 10014657536.0000\n",
      "Epoch 200/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9442945024.0000 - val_loss: 10224106496.0000\n",
      "Epoch 201/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 9461454848.0000 - val_loss: 10009744384.0000\n",
      "Epoch 202/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9484101632.0000 - val_loss: 9998236672.0000\n",
      "Epoch 203/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9472788480.0000 - val_loss: 10015369216.0000\n",
      "Epoch 204/1500\n",
      "119/119 [==============================] - 0s 901us/step - loss: 9391528960.0000 - val_loss: 10079149056.0000\n",
      "Epoch 205/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9558970368.0000 - val_loss: 10220286976.0000\n",
      "Epoch 206/1500\n",
      "119/119 [==============================] - 0s 914us/step - loss: 9605561344.0000 - val_loss: 9970833408.0000\n",
      "Epoch 207/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9606626304.0000 - val_loss: 10015122432.0000\n",
      "Epoch 208/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9450329088.0000 - val_loss: 10026360832.0000\n",
      "Epoch 209/1500\n",
      "119/119 [==============================] - 0s 940us/step - loss: 9336090624.0000 - val_loss: 10593851392.0000\n",
      "Epoch 210/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9484398592.0000 - val_loss: 9895369728.0000\n",
      "Epoch 211/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9359472640.0000 - val_loss: 10221677568.0000\n",
      "Epoch 212/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9366996992.0000 - val_loss: 10020633600.0000\n",
      "Epoch 213/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9259453440.0000 - val_loss: 9946310656.0000\n",
      "Epoch 214/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9435766784.0000 - val_loss: 9870282752.0000\n",
      "Epoch 215/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9445026816.0000 - val_loss: 9860346880.0000\n",
      "Epoch 216/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9319913472.0000 - val_loss: 9870637056.0000\n",
      "Epoch 217/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9503629312.0000 - val_loss: 9928861696.0000\n",
      "Epoch 218/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9412608000.0000 - val_loss: 10248730624.0000\n",
      "Epoch 219/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9365292032.0000 - val_loss: 9816738816.0000\n",
      "Epoch 220/1500\n",
      "119/119 [==============================] - 0s 905us/step - loss: 9407715328.0000 - val_loss: 9872959488.0000\n",
      "Epoch 221/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9227976704.0000 - val_loss: 9796200448.0000\n",
      "Epoch 222/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9295568896.0000 - val_loss: 9815013376.0000\n",
      "Epoch 223/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9220126720.0000 - val_loss: 10340318208.0000\n",
      "Epoch 224/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9331602432.0000 - val_loss: 9909801984.0000\n",
      "Epoch 225/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9378939904.0000 - val_loss: 10154245120.0000\n",
      "Epoch 226/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9308054528.0000 - val_loss: 9799494656.0000\n",
      "Epoch 227/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9232723968.0000 - val_loss: 9915932672.0000\n",
      "Epoch 228/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9228552192.0000 - val_loss: 9752942592.0000\n",
      "Epoch 229/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 9426866176.0000 - val_loss: 10098579456.0000\n",
      "Epoch 230/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9529982976.0000 - val_loss: 9736727552.0000\n",
      "Epoch 231/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 9355811840.0000 - val_loss: 10669702144.0000\n",
      "Epoch 232/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 9673512960.0000 - val_loss: 9717302272.0000\n",
      "Epoch 233/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9252687872.0000 - val_loss: 9826803712.0000\n",
      "Epoch 234/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9276478464.0000 - val_loss: 10063184896.0000\n",
      "Epoch 235/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9389598720.0000 - val_loss: 9704806400.0000\n",
      "Epoch 236/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 9315918848.0000 - val_loss: 9723715584.0000\n",
      "Epoch 237/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9293232128.0000 - val_loss: 9882316800.0000\n",
      "Epoch 238/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9312276480.0000 - val_loss: 10423832576.0000\n",
      "Epoch 239/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 9131078656.0000 - val_loss: 9723885568.0000\n",
      "Epoch 240/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9269539840.0000 - val_loss: 10056673280.0000\n",
      "Epoch 241/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9169937408.0000 - val_loss: 9947901952.0000\n",
      "Epoch 242/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 9399219200.0000 - val_loss: 9669555200.0000\n",
      "Epoch 243/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9222737920.0000 - val_loss: 9878220800.0000\n",
      "Epoch 244/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9099523072.0000 - val_loss: 9671915520.0000\n",
      "Epoch 245/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 9238065152.0000 - val_loss: 10943174656.0000\n",
      "Epoch 246/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9369051136.0000 - val_loss: 9880987648.0000\n",
      "Epoch 247/1500\n",
      "119/119 [==============================] - 0s 975us/step - loss: 9174074368.0000 - val_loss: 9604605952.0000\n",
      "Epoch 248/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 9144133632.0000 - val_loss: 10306052096.0000\n",
      "Epoch 249/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9235345408.0000 - val_loss: 9595017216.0000\n",
      "Epoch 250/1500\n",
      "119/119 [==============================] - 0s 942us/step - loss: 9013303296.0000 - val_loss: 9588736000.0000\n",
      "Epoch 251/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 9058407424.0000 - val_loss: 10237326336.0000\n",
      "Epoch 252/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 9188118528.0000 - val_loss: 9646981120.0000\n",
      "Epoch 253/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9100033024.0000 - val_loss: 9578875904.0000\n",
      "Epoch 254/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9218930688.0000 - val_loss: 9584539648.0000\n",
      "Epoch 255/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 9294525440.0000 - val_loss: 9704667136.0000\n",
      "Epoch 256/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9174063104.0000 - val_loss: 9742278656.0000\n",
      "Epoch 257/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 9148072960.0000 - val_loss: 9601283072.0000\n",
      "Epoch 258/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9042547712.0000 - val_loss: 10829980672.0000\n",
      "Epoch 259/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9109079040.0000 - val_loss: 9723706368.0000\n",
      "Epoch 260/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9125234688.0000 - val_loss: 11652573184.0000\n",
      "Epoch 261/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9341675520.0000 - val_loss: 9642684416.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9114932224.0000 - val_loss: 9772966912.0000\n",
      "Epoch 263/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9074997248.0000 - val_loss: 9702352896.0000\n",
      "Epoch 264/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9043078144.0000 - val_loss: 9676362752.0000\n",
      "Epoch 265/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9020267520.0000 - val_loss: 9615594496.0000\n",
      "Epoch 266/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9135263744.0000 - val_loss: 9609654272.0000\n",
      "Epoch 267/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9070520320.0000 - val_loss: 10064950272.0000\n",
      "Epoch 268/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9198440448.0000 - val_loss: 10395586560.0000\n",
      "Epoch 269/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8899815424.0000 - val_loss: 11237883904.0000\n",
      "Epoch 270/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9089167360.0000 - val_loss: 9463384064.0000\n",
      "Epoch 271/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9043630080.0000 - val_loss: 9492435968.0000\n",
      "Epoch 272/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8938672128.0000 - val_loss: 11523174400.0000\n",
      "Epoch 273/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 9075110912.0000 - val_loss: 9502152704.0000\n",
      "Epoch 274/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 9031387136.0000 - val_loss: 9983182848.0000\n",
      "Epoch 275/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8997705728.0000 - val_loss: 10210724864.0000\n",
      "Epoch 276/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8966546432.0000 - val_loss: 9491483648.0000\n",
      "Epoch 277/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8858142720.0000 - val_loss: 9516525568.0000\n",
      "Epoch 278/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8924575744.0000 - val_loss: 9604642816.0000\n",
      "Epoch 279/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8972672000.0000 - val_loss: 9471382528.0000\n",
      "Epoch 280/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 9002870784.0000 - val_loss: 9675036672.0000\n",
      "Epoch 281/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8973391872.0000 - val_loss: 9685181440.0000\n",
      "Epoch 282/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 9112343552.0000 - val_loss: 9460111360.0000\n",
      "Epoch 283/1500\n",
      "119/119 [==============================] - 0s 983us/step - loss: 8936550400.0000 - val_loss: 9487848448.0000\n",
      "Epoch 284/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8933884928.0000 - val_loss: 9360121856.0000\n",
      "Epoch 285/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9064934400.0000 - val_loss: 9416754176.0000\n",
      "Epoch 286/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9032750080.0000 - val_loss: 10871707648.0000\n",
      "Epoch 287/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 9255860224.0000 - val_loss: 9421989888.0000\n",
      "Epoch 288/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8956485632.0000 - val_loss: 9542844416.0000\n",
      "Epoch 289/1500\n",
      "119/119 [==============================] - 0s 983us/step - loss: 8960592896.0000 - val_loss: 9368114176.0000\n",
      "Epoch 290/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8912661504.0000 - val_loss: 9342556160.0000\n",
      "Epoch 291/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8939279360.0000 - val_loss: 9834719232.0000\n",
      "Epoch 292/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8840062976.0000 - val_loss: 9732660224.0000\n",
      "Epoch 293/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8857659392.0000 - val_loss: 9312362496.0000\n",
      "Epoch 294/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8801184768.0000 - val_loss: 9987572736.0000\n",
      "Epoch 295/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8825135104.0000 - val_loss: 9517539328.0000\n",
      "Epoch 296/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8903726080.0000 - val_loss: 9301742592.0000\n",
      "Epoch 297/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8801000448.0000 - val_loss: 9765525504.0000\n",
      "Epoch 298/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 9014880256.0000 - val_loss: 9498083328.0000\n",
      "Epoch 299/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8757457920.0000 - val_loss: 9399246848.0000\n",
      "Epoch 300/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9101771776.0000 - val_loss: 9821184000.0000\n",
      "Epoch 301/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8841924608.0000 - val_loss: 9296638976.0000\n",
      "Epoch 302/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8826554368.0000 - val_loss: 9296531456.0000\n",
      "Epoch 303/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8844503040.0000 - val_loss: 9572926464.0000\n",
      "Epoch 304/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8887184384.0000 - val_loss: 9266415616.0000\n",
      "Epoch 305/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8857792512.0000 - val_loss: 9345988608.0000\n",
      "Epoch 306/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8944948224.0000 - val_loss: 9595203584.0000\n",
      "Epoch 307/1500\n",
      "119/119 [==============================] - 0s 992us/step - loss: 8905050112.0000 - val_loss: 9312661504.0000\n",
      "Epoch 308/1500\n",
      "119/119 [==============================] - 0s 975us/step - loss: 9022668800.0000 - val_loss: 9321984000.0000\n",
      "Epoch 309/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8764016640.0000 - val_loss: 10432522240.0000\n",
      "Epoch 310/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8787748864.0000 - val_loss: 9375902720.0000\n",
      "Epoch 311/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8937480192.0000 - val_loss: 9221711872.0000\n",
      "Epoch 312/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 9038006272.0000 - val_loss: 9214944256.0000\n",
      "Epoch 313/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8771783680.0000 - val_loss: 9369797632.0000\n",
      "Epoch 314/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8787921920.0000 - val_loss: 9407043584.0000\n",
      "Epoch 315/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8725331968.0000 - val_loss: 9255037952.0000\n",
      "Epoch 316/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 9050332160.0000 - val_loss: 9252745216.0000\n",
      "Epoch 317/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8885928960.0000 - val_loss: 9215027200.0000\n",
      "Epoch 318/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8821019648.0000 - val_loss: 9231796224.0000\n",
      "Epoch 319/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8738564096.0000 - val_loss: 9209528320.0000\n",
      "Epoch 320/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8752884736.0000 - val_loss: 9305401344.0000\n",
      "Epoch 321/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8744075264.0000 - val_loss: 9179361280.0000\n",
      "Epoch 322/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8782965760.0000 - val_loss: 9202974720.0000\n",
      "Epoch 323/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8720471040.0000 - val_loss: 9184532480.0000\n",
      "Epoch 324/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8980740096.0000 - val_loss: 9475755008.0000\n",
      "Epoch 325/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8852927488.0000 - val_loss: 9393532928.0000\n",
      "Epoch 326/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8675869696.0000 - val_loss: 9197911040.0000\n",
      "Epoch 327/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8775834624.0000 - val_loss: 9407281152.0000\n",
      "Epoch 328/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 915us/step - loss: 8851022848.0000 - val_loss: 9615311872.0000\n",
      "Epoch 329/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8744058880.0000 - val_loss: 9173365760.0000\n",
      "Epoch 330/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8791812096.0000 - val_loss: 10089778176.0000\n",
      "Epoch 331/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8783263744.0000 - val_loss: 9145823232.0000\n",
      "Epoch 332/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8644219904.0000 - val_loss: 9743158272.0000\n",
      "Epoch 333/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8798425088.0000 - val_loss: 9155401728.0000\n",
      "Epoch 334/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8663166976.0000 - val_loss: 9193310208.0000\n",
      "Epoch 335/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8819411968.0000 - val_loss: 10621405184.0000\n",
      "Epoch 336/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8735862784.0000 - val_loss: 9489868800.0000\n",
      "Epoch 337/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8884800512.0000 - val_loss: 9311669248.0000\n",
      "Epoch 338/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8663309312.0000 - val_loss: 9137297408.0000\n",
      "Epoch 339/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8671293440.0000 - val_loss: 9751394304.0000\n",
      "Epoch 340/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8805633024.0000 - val_loss: 9139181568.0000\n",
      "Epoch 341/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8714923008.0000 - val_loss: 10165866496.0000\n",
      "Epoch 342/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8996875264.0000 - val_loss: 9209457664.0000\n",
      "Epoch 343/1500\n",
      "119/119 [==============================] - 0s 908us/step - loss: 8638745600.0000 - val_loss: 9186577408.0000\n",
      "Epoch 344/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8627989504.0000 - val_loss: 9142361088.0000\n",
      "Epoch 345/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8896031744.0000 - val_loss: 9295550464.0000\n",
      "Epoch 346/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8548989440.0000 - val_loss: 9095713792.0000\n",
      "Epoch 347/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8602693632.0000 - val_loss: 9094724608.0000\n",
      "Epoch 348/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8602389504.0000 - val_loss: 9383308288.0000\n",
      "Epoch 349/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8561203712.0000 - val_loss: 9310833664.0000\n",
      "Epoch 350/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8664561664.0000 - val_loss: 9087282176.0000\n",
      "Epoch 351/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8665437184.0000 - val_loss: 9201000448.0000\n",
      "Epoch 352/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8710948864.0000 - val_loss: 9171459072.0000\n",
      "Epoch 353/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8578696704.0000 - val_loss: 9233683456.0000\n",
      "Epoch 354/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8989455360.0000 - val_loss: 9379993600.0000\n",
      "Epoch 355/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8753361920.0000 - val_loss: 9287859200.0000\n",
      "Epoch 356/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8514875392.0000 - val_loss: 9478463488.0000\n",
      "Epoch 357/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8687251456.0000 - val_loss: 10600295424.0000\n",
      "Epoch 358/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8646650880.0000 - val_loss: 9144110080.0000\n",
      "Epoch 359/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8615072768.0000 - val_loss: 9365764096.0000\n",
      "Epoch 360/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8706756608.0000 - val_loss: 9071411200.0000\n",
      "Epoch 361/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8732051456.0000 - val_loss: 9212581888.0000\n",
      "Epoch 362/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8618578944.0000 - val_loss: 9191060480.0000\n",
      "Epoch 363/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8638835712.0000 - val_loss: 9667502080.0000\n",
      "Epoch 364/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8586081792.0000 - val_loss: 9435808768.0000\n",
      "Epoch 365/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8656999424.0000 - val_loss: 9047396352.0000\n",
      "Epoch 366/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 8741065728.0000 - val_loss: 9145965568.0000\n",
      "Epoch 367/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8604682240.0000 - val_loss: 9914622976.0000\n",
      "Epoch 368/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8567255040.0000 - val_loss: 9373960192.0000\n",
      "Epoch 369/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8572690432.0000 - val_loss: 9048872960.0000\n",
      "Epoch 370/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 8510524416.0000 - val_loss: 9078916096.0000\n",
      "Epoch 371/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 8547985408.0000 - val_loss: 9082354688.0000\n",
      "Epoch 372/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8675591168.0000 - val_loss: 9613805568.0000\n",
      "Epoch 373/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8480788992.0000 - val_loss: 9052777472.0000\n",
      "Epoch 374/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8579437568.0000 - val_loss: 9036114944.0000\n",
      "Epoch 375/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8526479872.0000 - val_loss: 9139358720.0000\n",
      "Epoch 376/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8494989312.0000 - val_loss: 9490548736.0000\n",
      "Epoch 377/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8661931008.0000 - val_loss: 9261172736.0000\n",
      "Epoch 378/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8550350848.0000 - val_loss: 9042204672.0000\n",
      "Epoch 379/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8498355200.0000 - val_loss: 8987264000.0000\n",
      "Epoch 380/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8521999360.0000 - val_loss: 9510274048.0000\n",
      "Epoch 381/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8715748352.0000 - val_loss: 9001062400.0000\n",
      "Epoch 382/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8506142208.0000 - val_loss: 9009063936.0000\n",
      "Epoch 383/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8466636288.0000 - val_loss: 10829363200.0000\n",
      "Epoch 384/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8629580800.0000 - val_loss: 8970736640.0000\n",
      "Epoch 385/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8479975424.0000 - val_loss: 9542612992.0000\n",
      "Epoch 386/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8479268352.0000 - val_loss: 9006690304.0000\n",
      "Epoch 387/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8429548544.0000 - val_loss: 9023149056.0000\n",
      "Epoch 388/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8498041344.0000 - val_loss: 9335052288.0000\n",
      "Epoch 389/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8642869248.0000 - val_loss: 9027238912.0000\n",
      "Epoch 390/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8626210816.0000 - val_loss: 9039343616.0000\n",
      "Epoch 391/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8476265472.0000 - val_loss: 9042728960.0000\n",
      "Epoch 392/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8494362112.0000 - val_loss: 9171980288.0000\n",
      "Epoch 393/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8560858624.0000 - val_loss: 8978973696.0000\n",
      "Epoch 394/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8835142656.0000 - val_loss: 9515746304.0000\n",
      "Epoch 395/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8463196160.0000 - val_loss: 9398119424.0000\n",
      "Epoch 396/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8433552384.0000 - val_loss: 9185876992.0000\n",
      "Epoch 397/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8523938304.0000 - val_loss: 9029629952.0000\n",
      "Epoch 398/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8776326144.0000 - val_loss: 8983890944.0000\n",
      "Epoch 399/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8641136640.0000 - val_loss: 9561417728.0000\n",
      "Epoch 400/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8539822080.0000 - val_loss: 9007956992.0000\n",
      "Epoch 401/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8424635392.0000 - val_loss: 9538184192.0000\n",
      "Epoch 402/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8647899136.0000 - val_loss: 9002124288.0000\n",
      "Epoch 403/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8356062208.0000 - val_loss: 10139754496.0000\n",
      "Epoch 404/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8516939776.0000 - val_loss: 9072763904.0000\n",
      "Epoch 405/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8448563200.0000 - val_loss: 8944943104.0000\n",
      "Epoch 406/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8366436352.0000 - val_loss: 9116638208.0000\n",
      "Epoch 407/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8398499840.0000 - val_loss: 8946423808.0000\n",
      "Epoch 408/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8490521088.0000 - val_loss: 8973078528.0000\n",
      "Epoch 409/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8536054784.0000 - val_loss: 10333094912.0000\n",
      "Epoch 410/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8492262400.0000 - val_loss: 8958013440.0000\n",
      "Epoch 411/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8426381824.0000 - val_loss: 9076476928.0000\n",
      "Epoch 412/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8429264384.0000 - val_loss: 9256994816.0000\n",
      "Epoch 413/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8416129024.0000 - val_loss: 9113859072.0000\n",
      "Epoch 414/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8446178304.0000 - val_loss: 9165804544.0000\n",
      "Epoch 415/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8376017408.0000 - val_loss: 8978421760.0000\n",
      "Epoch 416/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8527172608.0000 - val_loss: 9095129088.0000\n",
      "Epoch 417/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8396684288.0000 - val_loss: 8993076224.0000\n",
      "Epoch 418/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8402511360.0000 - val_loss: 8923593728.0000\n",
      "Epoch 419/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8487129088.0000 - val_loss: 10131153920.0000\n",
      "Epoch 420/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8457105920.0000 - val_loss: 8903291904.0000\n",
      "Epoch 421/1500\n",
      "119/119 [==============================] - 0s 983us/step - loss: 8322139648.0000 - val_loss: 8877731840.0000\n",
      "Epoch 422/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8438174208.0000 - val_loss: 9025047552.0000\n",
      "Epoch 423/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8372310016.0000 - val_loss: 9475910656.0000\n",
      "Epoch 424/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8421200896.0000 - val_loss: 8977387520.0000\n",
      "Epoch 425/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8412899840.0000 - val_loss: 8880052224.0000\n",
      "Epoch 426/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8472161792.0000 - val_loss: 9244106752.0000\n",
      "Epoch 427/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8342201344.0000 - val_loss: 8905589760.0000\n",
      "Epoch 428/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8589589504.0000 - val_loss: 10088346624.0000\n",
      "Epoch 429/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8881331200.0000 - val_loss: 9268788224.0000\n",
      "Epoch 430/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8414003200.0000 - val_loss: 9360876544.0000\n",
      "Epoch 431/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8379237888.0000 - val_loss: 8918500352.0000\n",
      "Epoch 432/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8556184576.0000 - val_loss: 9579339776.0000\n",
      "Epoch 433/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8426906624.0000 - val_loss: 9004091392.0000\n",
      "Epoch 434/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8287006720.0000 - val_loss: 8885824512.0000\n",
      "Epoch 435/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8307061760.0000 - val_loss: 10904801280.0000\n",
      "Epoch 436/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8382989824.0000 - val_loss: 8982431744.0000\n",
      "Epoch 437/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8371068928.0000 - val_loss: 8859731968.0000\n",
      "Epoch 438/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8903149568.0000 - val_loss: 10324698112.0000\n",
      "Epoch 439/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8692933632.0000 - val_loss: 8848726016.0000\n",
      "Epoch 440/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8334427648.0000 - val_loss: 8866775040.0000\n",
      "Epoch 441/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8531780608.0000 - val_loss: 8885575680.0000\n",
      "Epoch 442/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8317798400.0000 - val_loss: 9204653056.0000\n",
      "Epoch 443/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8255375872.0000 - val_loss: 9209945088.0000\n",
      "Epoch 444/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8432907264.0000 - val_loss: 8872148992.0000\n",
      "Epoch 445/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8453316096.0000 - val_loss: 8870504448.0000\n",
      "Epoch 446/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8499949568.0000 - val_loss: 9233076224.0000\n",
      "Epoch 447/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8325150208.0000 - val_loss: 9954244608.0000\n",
      "Epoch 448/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8578074624.0000 - val_loss: 8837181440.0000\n",
      "Epoch 449/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8489629696.0000 - val_loss: 9782994944.0000\n",
      "Epoch 450/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8473351168.0000 - val_loss: 8937729024.0000\n",
      "Epoch 451/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8278796800.0000 - val_loss: 9356417024.0000\n",
      "Epoch 452/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8231687680.0000 - val_loss: 9221320704.0000\n",
      "Epoch 453/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8329063424.0000 - val_loss: 8909488128.0000\n",
      "Epoch 454/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8305084928.0000 - val_loss: 9354366976.0000\n",
      "Epoch 455/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8346108928.0000 - val_loss: 8883352576.0000\n",
      "Epoch 456/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8213400064.0000 - val_loss: 9337001984.0000\n",
      "Epoch 457/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8300808192.0000 - val_loss: 8831529984.0000\n",
      "Epoch 458/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8257375232.0000 - val_loss: 10244842496.0000\n",
      "Epoch 459/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8300016128.0000 - val_loss: 8894560256.0000\n",
      "Epoch 460/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 907us/step - loss: 8357520384.0000 - val_loss: 9102305280.0000\n",
      "Epoch 461/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8369983488.0000 - val_loss: 9170941952.0000\n",
      "Epoch 462/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 8351813120.0000 - val_loss: 8786854912.0000\n",
      "Epoch 463/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8260051968.0000 - val_loss: 8793055232.0000\n",
      "Epoch 464/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8401717248.0000 - val_loss: 9337548800.0000\n",
      "Epoch 465/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8366192128.0000 - val_loss: 8905553920.0000\n",
      "Epoch 466/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8400689664.0000 - val_loss: 8844296192.0000\n",
      "Epoch 467/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8373913088.0000 - val_loss: 8978497536.0000\n",
      "Epoch 468/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8211661312.0000 - val_loss: 9002164224.0000\n",
      "Epoch 469/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8322206720.0000 - val_loss: 9076620288.0000\n",
      "Epoch 470/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8229847040.0000 - val_loss: 8787205120.0000\n",
      "Epoch 471/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8250509824.0000 - val_loss: 8982308864.0000\n",
      "Epoch 472/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8405197824.0000 - val_loss: 9499386880.0000\n",
      "Epoch 473/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8386591744.0000 - val_loss: 8788623360.0000\n",
      "Epoch 474/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8399428096.0000 - val_loss: 8755601408.0000\n",
      "Epoch 475/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8186155008.0000 - val_loss: 9958949888.0000\n",
      "Epoch 476/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8430958080.0000 - val_loss: 8762267648.0000\n",
      "Epoch 477/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8185962496.0000 - val_loss: 8826149888.0000\n",
      "Epoch 478/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8342733312.0000 - val_loss: 8790960128.0000\n",
      "Epoch 479/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8364855296.0000 - val_loss: 9372759040.0000\n",
      "Epoch 480/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8213974528.0000 - val_loss: 8777274368.0000\n",
      "Epoch 481/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8354091520.0000 - val_loss: 8883408896.0000\n",
      "Epoch 482/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8390253056.0000 - val_loss: 8772334592.0000\n",
      "Epoch 483/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8316557312.0000 - val_loss: 9659063296.0000\n",
      "Epoch 484/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8241660416.0000 - val_loss: 8857550848.0000\n",
      "Epoch 485/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8195515904.0000 - val_loss: 8841068544.0000\n",
      "Epoch 486/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8204180992.0000 - val_loss: 9161259008.0000\n",
      "Epoch 487/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8370093568.0000 - val_loss: 9312376832.0000\n",
      "Epoch 488/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8193028608.0000 - val_loss: 8775110656.0000\n",
      "Epoch 489/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8550033408.0000 - val_loss: 9017262080.0000\n",
      "Epoch 490/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8189617152.0000 - val_loss: 8802274304.0000\n",
      "Epoch 491/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8382376960.0000 - val_loss: 8785606656.0000\n",
      "Epoch 492/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8414269440.0000 - val_loss: 9779777536.0000\n",
      "Epoch 493/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8451766272.0000 - val_loss: 9178888192.0000\n",
      "Epoch 494/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8258203648.0000 - val_loss: 9359271936.0000\n",
      "Epoch 495/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8658004992.0000 - val_loss: 8851052544.0000\n",
      "Epoch 496/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8343989760.0000 - val_loss: 8903291904.0000\n",
      "Epoch 497/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8126930432.0000 - val_loss: 8796581888.0000\n",
      "Epoch 498/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8137653760.0000 - val_loss: 8741355520.0000\n",
      "Epoch 499/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8406739456.0000 - val_loss: 8754551808.0000\n",
      "Epoch 500/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8147469312.0000 - val_loss: 8729388032.0000\n",
      "Epoch 501/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8161369088.0000 - val_loss: 8806238208.0000\n",
      "Epoch 502/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8324240384.0000 - val_loss: 8865990656.0000\n",
      "Epoch 503/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8441198592.0000 - val_loss: 8749723648.0000\n",
      "Epoch 504/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8187182592.0000 - val_loss: 8856410112.0000\n",
      "Epoch 505/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8311463936.0000 - val_loss: 8837081088.0000\n",
      "Epoch 506/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8261073408.0000 - val_loss: 8787570688.0000\n",
      "Epoch 507/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8141259264.0000 - val_loss: 8991602688.0000\n",
      "Epoch 508/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8127237120.0000 - val_loss: 8845312000.0000\n",
      "Epoch 509/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8266864128.0000 - val_loss: 8725756928.0000\n",
      "Epoch 510/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8355797504.0000 - val_loss: 8961959936.0000\n",
      "Epoch 511/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8244147200.0000 - val_loss: 9518226432.0000\n",
      "Epoch 512/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8173283840.0000 - val_loss: 8712248320.0000\n",
      "Epoch 513/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8306504704.0000 - val_loss: 9194236928.0000\n",
      "Epoch 514/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8128685056.0000 - val_loss: 8757519360.0000\n",
      "Epoch 515/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8399993344.0000 - val_loss: 8805536768.0000\n",
      "Epoch 516/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8187039232.0000 - val_loss: 8761090048.0000\n",
      "Epoch 517/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8102216192.0000 - val_loss: 8748921856.0000\n",
      "Epoch 518/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8260935168.0000 - val_loss: 9439341568.0000\n",
      "Epoch 519/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8200866304.0000 - val_loss: 10080892928.0000\n",
      "Epoch 520/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8218007552.0000 - val_loss: 8745133056.0000\n",
      "Epoch 521/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8086135296.0000 - val_loss: 8729762816.0000\n",
      "Epoch 522/1500\n",
      "119/119 [==============================] - 0s 891us/step - loss: 8101331968.0000 - val_loss: 9161388032.0000\n",
      "Epoch 523/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8514900992.0000 - val_loss: 9993835520.0000\n",
      "Epoch 524/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8088002048.0000 - val_loss: 8760424448.0000\n",
      "Epoch 525/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8159427584.0000 - val_loss: 8688384000.0000\n",
      "Epoch 526/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8143956480.0000 - val_loss: 9277374464.0000\n",
      "Epoch 527/1500\n",
      "119/119 [==============================] - 0s 923us/step - loss: 8266636800.0000 - val_loss: 8697690112.0000\n",
      "Epoch 528/1500\n",
      "119/119 [==============================] - 0s 908us/step - loss: 8450357248.0000 - val_loss: 8853262336.0000\n",
      "Epoch 529/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8127853056.0000 - val_loss: 8761336832.0000\n",
      "Epoch 530/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8096211968.0000 - val_loss: 9199736832.0000\n",
      "Epoch 531/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8464248320.0000 - val_loss: 9024365568.0000\n",
      "Epoch 532/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8080448000.0000 - val_loss: 8903168000.0000\n",
      "Epoch 533/1500\n",
      "119/119 [==============================] - 0s 930us/step - loss: 8271065088.0000 - val_loss: 8827423744.0000\n",
      "Epoch 534/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8226151936.0000 - val_loss: 9452575744.0000\n",
      "Epoch 535/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8096631808.0000 - val_loss: 9169997824.0000\n",
      "Epoch 536/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8174894592.0000 - val_loss: 9232433152.0000\n",
      "Epoch 537/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8518583296.0000 - val_loss: 8857234432.0000\n",
      "Epoch 538/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8262556672.0000 - val_loss: 8742053888.0000\n",
      "Epoch 539/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8078403072.0000 - val_loss: 8711535616.0000\n",
      "Epoch 540/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8052496896.0000 - val_loss: 8652700672.0000\n",
      "Epoch 541/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8294472704.0000 - val_loss: 9536727040.0000\n",
      "Epoch 542/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8207109632.0000 - val_loss: 9568210944.0000\n",
      "Epoch 543/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8128371200.0000 - val_loss: 8926995456.0000\n",
      "Epoch 544/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8290236416.0000 - val_loss: 9185164288.0000\n",
      "Epoch 545/1500\n",
      "119/119 [==============================] - 0s 885us/step - loss: 8157127168.0000 - val_loss: 8787992576.0000\n",
      "Epoch 546/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8146823680.0000 - val_loss: 8715883520.0000\n",
      "Epoch 547/1500\n",
      "119/119 [==============================] - 0s 897us/step - loss: 8314008576.0000 - val_loss: 9793983488.0000\n",
      "Epoch 548/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8099753984.0000 - val_loss: 8688996352.0000\n",
      "Epoch 549/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8024528896.0000 - val_loss: 9392331776.0000\n",
      "Epoch 550/1500\n",
      "119/119 [==============================] - 0s 893us/step - loss: 8043546624.0000 - val_loss: 9274979328.0000\n",
      "Epoch 551/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8203450368.0000 - val_loss: 8746381312.0000\n",
      "Epoch 552/1500\n",
      "119/119 [==============================] - 0s 900us/step - loss: 8395221504.0000 - val_loss: 8882891776.0000\n",
      "Epoch 553/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8000557056.0000 - val_loss: 8654078976.0000\n",
      "Epoch 554/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8206927872.0000 - val_loss: 8694961152.0000\n",
      "Epoch 555/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8090389504.0000 - val_loss: 8657208320.0000\n",
      "Epoch 556/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8065042432.0000 - val_loss: 8667025408.0000\n",
      "Epoch 557/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7970699776.0000 - val_loss: 8826862592.0000\n",
      "Epoch 558/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8001229824.0000 - val_loss: 8631934976.0000\n",
      "Epoch 559/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8309848576.0000 - val_loss: 8719509504.0000\n",
      "Epoch 560/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8139507200.0000 - val_loss: 9318979584.0000\n",
      "Epoch 561/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8462324224.0000 - val_loss: 8737012736.0000\n",
      "Epoch 562/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8016331776.0000 - val_loss: 9013805056.0000\n",
      "Epoch 563/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8070102528.0000 - val_loss: 8734206976.0000\n",
      "Epoch 564/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8178592256.0000 - val_loss: 9152928768.0000\n",
      "Epoch 565/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8230298112.0000 - val_loss: 8856610816.0000\n",
      "Epoch 566/1500\n",
      "119/119 [==============================] - 0s 881us/step - loss: 8481229312.0000 - val_loss: 8734013440.0000\n",
      "Epoch 567/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8129032704.0000 - val_loss: 8658029568.0000\n",
      "Epoch 568/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8090306560.0000 - val_loss: 8645797888.0000\n",
      "Epoch 569/1500\n",
      "119/119 [==============================] - 0s 881us/step - loss: 8079976960.0000 - val_loss: 9605260288.0000\n",
      "Epoch 570/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7989357056.0000 - val_loss: 8691594240.0000\n",
      "Epoch 571/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8048095232.0000 - val_loss: 8861685760.0000\n",
      "Epoch 572/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8140492800.0000 - val_loss: 8667798528.0000\n",
      "Epoch 573/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8164063744.0000 - val_loss: 9741765632.0000\n",
      "Epoch 574/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8128936448.0000 - val_loss: 8784015360.0000\n",
      "Epoch 575/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7979027456.0000 - val_loss: 8774772736.0000\n",
      "Epoch 576/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8421980160.0000 - val_loss: 9580977152.0000\n",
      "Epoch 577/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8120040448.0000 - val_loss: 8681977856.0000\n",
      "Epoch 578/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7997594624.0000 - val_loss: 8613350400.0000\n",
      "Epoch 579/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8236284928.0000 - val_loss: 8773144576.0000\n",
      "Epoch 580/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7953844224.0000 - val_loss: 9729186816.0000\n",
      "Epoch 581/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8064711680.0000 - val_loss: 8600161280.0000\n",
      "Epoch 582/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8089524224.0000 - val_loss: 8638949376.0000\n",
      "Epoch 583/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8430207488.0000 - val_loss: 9834059776.0000\n",
      "Epoch 584/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8202036224.0000 - val_loss: 10111861760.0000\n",
      "Epoch 585/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7932198400.0000 - val_loss: 8900079616.0000\n",
      "Epoch 586/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7946650624.0000 - val_loss: 8616515584.0000\n",
      "Epoch 587/1500\n",
      "119/119 [==============================] - 0s 889us/step - loss: 8054101504.0000 - val_loss: 8621033472.0000\n",
      "Epoch 588/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8178967040.0000 - val_loss: 8698745856.0000\n",
      "Epoch 589/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8027452928.0000 - val_loss: 8876513280.0000\n",
      "Epoch 590/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8113710080.0000 - val_loss: 9368252416.0000\n",
      "Epoch 591/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8026466304.0000 - val_loss: 8574860288.0000\n",
      "Epoch 592/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 890us/step - loss: 8055702016.0000 - val_loss: 8596483072.0000\n",
      "Epoch 593/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7992933888.0000 - val_loss: 9264566272.0000\n",
      "Epoch 594/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8196692992.0000 - val_loss: 8661779456.0000\n",
      "Epoch 595/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8216374784.0000 - val_loss: 8664279040.0000\n",
      "Epoch 596/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8140709376.0000 - val_loss: 8675821568.0000\n",
      "Epoch 597/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8178484224.0000 - val_loss: 10931662848.0000\n",
      "Epoch 598/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8078240768.0000 - val_loss: 9045493760.0000\n",
      "Epoch 599/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8157056000.0000 - val_loss: 8704375808.0000\n",
      "Epoch 600/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8031774720.0000 - val_loss: 11113803776.0000\n",
      "Epoch 601/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7986935296.0000 - val_loss: 8747759616.0000\n",
      "Epoch 602/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7920337408.0000 - val_loss: 8675992576.0000\n",
      "Epoch 603/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7979013120.0000 - val_loss: 8604197888.0000\n",
      "Epoch 604/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8238954496.0000 - val_loss: 8585059840.0000\n",
      "Epoch 605/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8000705024.0000 - val_loss: 8761949184.0000\n",
      "Epoch 606/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8227581440.0000 - val_loss: 8904170496.0000\n",
      "Epoch 607/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8223648768.0000 - val_loss: 8587632640.0000\n",
      "Epoch 608/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7994666496.0000 - val_loss: 8573306880.0000\n",
      "Epoch 609/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8024230912.0000 - val_loss: 8835521536.0000\n",
      "Epoch 610/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8247708672.0000 - val_loss: 8569963008.0000\n",
      "Epoch 611/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7897883648.0000 - val_loss: 8576104448.0000\n",
      "Epoch 612/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7946296832.0000 - val_loss: 8656988160.0000\n",
      "Epoch 613/1500\n",
      "119/119 [==============================] - 0s 900us/step - loss: 8083770880.0000 - val_loss: 8809952256.0000\n",
      "Epoch 614/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8114612736.0000 - val_loss: 8889862144.0000\n",
      "Epoch 615/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8006728192.0000 - val_loss: 8620865536.0000\n",
      "Epoch 616/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8146373632.0000 - val_loss: 8555580416.0000\n",
      "Epoch 617/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8015570944.0000 - val_loss: 8687835136.0000\n",
      "Epoch 618/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8418701312.0000 - val_loss: 8667144192.0000\n",
      "Epoch 619/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8348549120.0000 - val_loss: 9524411392.0000\n",
      "Epoch 620/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8002179584.0000 - val_loss: 9139335168.0000\n",
      "Epoch 621/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8103787008.0000 - val_loss: 8672007168.0000\n",
      "Epoch 622/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7945624576.0000 - val_loss: 8627827712.0000\n",
      "Epoch 623/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7981822464.0000 - val_loss: 8619371520.0000\n",
      "Epoch 624/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8313938944.0000 - val_loss: 8650160128.0000\n",
      "Epoch 625/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7964141056.0000 - val_loss: 8647367680.0000\n",
      "Epoch 626/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8201037824.0000 - val_loss: 8874993664.0000\n",
      "Epoch 627/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8028100096.0000 - val_loss: 8668522496.0000\n",
      "Epoch 628/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7961010688.0000 - val_loss: 8571002880.0000\n",
      "Epoch 629/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7958115840.0000 - val_loss: 8575435776.0000\n",
      "Epoch 630/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7876991488.0000 - val_loss: 8618093568.0000\n",
      "Epoch 631/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8171576320.0000 - val_loss: 8870932480.0000\n",
      "Epoch 632/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8040336896.0000 - val_loss: 8581057024.0000\n",
      "Epoch 633/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7923451392.0000 - val_loss: 8915736576.0000\n",
      "Epoch 634/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8026314240.0000 - val_loss: 9308269568.0000\n",
      "Epoch 635/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7972696064.0000 - val_loss: 9287957504.0000\n",
      "Epoch 636/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7995330048.0000 - val_loss: 8638971904.0000\n",
      "Epoch 637/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8010027008.0000 - val_loss: 8911770624.0000\n",
      "Epoch 638/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7947158016.0000 - val_loss: 8614724608.0000\n",
      "Epoch 639/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7876704768.0000 - val_loss: 8658185216.0000\n",
      "Epoch 640/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7871554048.0000 - val_loss: 8560472576.0000\n",
      "Epoch 641/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7995243520.0000 - val_loss: 8839603200.0000\n",
      "Epoch 642/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8006026240.0000 - val_loss: 8567162880.0000\n",
      "Epoch 643/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8065449984.0000 - val_loss: 9000892416.0000\n",
      "Epoch 644/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7951576576.0000 - val_loss: 9021441024.0000\n",
      "Epoch 645/1500\n",
      "119/119 [==============================] - 0s 916us/step - loss: 8243466752.0000 - val_loss: 8574074368.0000\n",
      "Epoch 646/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 8099523072.0000 - val_loss: 9199357952.0000\n",
      "Epoch 647/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7976595968.0000 - val_loss: 9082599424.0000\n",
      "Epoch 648/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7842223104.0000 - val_loss: 8570119168.0000\n",
      "Epoch 649/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7947829760.0000 - val_loss: 8589754880.0000\n",
      "Epoch 650/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8191203840.0000 - val_loss: 8560967680.0000\n",
      "Epoch 651/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7927418368.0000 - val_loss: 8556684288.0000\n",
      "Epoch 652/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8029377536.0000 - val_loss: 8907101184.0000\n",
      "Epoch 653/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7908110848.0000 - val_loss: 8985759744.0000\n",
      "Epoch 654/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8292897792.0000 - val_loss: 9578776576.0000\n",
      "Epoch 655/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8038512640.0000 - val_loss: 9010777088.0000\n",
      "Epoch 656/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7966929920.0000 - val_loss: 8549140480.0000\n",
      "Epoch 657/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7955483136.0000 - val_loss: 9078695936.0000\n",
      "Epoch 658/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8028573184.0000 - val_loss: 8535983616.0000\n",
      "Epoch 659/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8078211072.0000 - val_loss: 8887081984.0000\n",
      "Epoch 660/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8034111488.0000 - val_loss: 8577843712.0000\n",
      "Epoch 661/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7919527936.0000 - val_loss: 8642676736.0000\n",
      "Epoch 662/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8052837376.0000 - val_loss: 8934178816.0000\n",
      "Epoch 663/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7938042880.0000 - val_loss: 8526041088.0000\n",
      "Epoch 664/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7889599488.0000 - val_loss: 8615967744.0000\n",
      "Epoch 665/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8029196800.0000 - val_loss: 8947287040.0000\n",
      "Epoch 666/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7992718848.0000 - val_loss: 8924361728.0000\n",
      "Epoch 667/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7872311296.0000 - val_loss: 8584102912.0000\n",
      "Epoch 668/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7933886976.0000 - val_loss: 8504811008.0000\n",
      "Epoch 669/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8011505664.0000 - val_loss: 8597638144.0000\n",
      "Epoch 670/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7845203968.0000 - val_loss: 8731220992.0000\n",
      "Epoch 671/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7921345024.0000 - val_loss: 8545348608.0000\n",
      "Epoch 672/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7883677696.0000 - val_loss: 8640557056.0000\n",
      "Epoch 673/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8175009280.0000 - val_loss: 8689145856.0000\n",
      "Epoch 674/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8035361280.0000 - val_loss: 8553383936.0000\n",
      "Epoch 675/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7869104640.0000 - val_loss: 8527680512.0000\n",
      "Epoch 676/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8009428992.0000 - val_loss: 8749457408.0000\n",
      "Epoch 677/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7883086848.0000 - val_loss: 9082088448.0000\n",
      "Epoch 678/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7833217536.0000 - val_loss: 8553593344.0000\n",
      "Epoch 679/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7837290496.0000 - val_loss: 8521729536.0000\n",
      "Epoch 680/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8183420928.0000 - val_loss: 8690662400.0000\n",
      "Epoch 681/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8241673728.0000 - val_loss: 9066033152.0000\n",
      "Epoch 682/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8055572480.0000 - val_loss: 8714707968.0000\n",
      "Epoch 683/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8154022912.0000 - val_loss: 8702002176.0000\n",
      "Epoch 684/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7774079488.0000 - val_loss: 8592275456.0000\n",
      "Epoch 685/1500\n",
      "119/119 [==============================] - 0s 881us/step - loss: 7864307712.0000 - val_loss: 8824348672.0000\n",
      "Epoch 686/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7915844608.0000 - val_loss: 9089575936.0000\n",
      "Epoch 687/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7880306176.0000 - val_loss: 8713005056.0000\n",
      "Epoch 688/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8059732480.0000 - val_loss: 8634610688.0000\n",
      "Epoch 689/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7835019776.0000 - val_loss: 9922738176.0000\n",
      "Epoch 690/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8226886656.0000 - val_loss: 8559548928.0000\n",
      "Epoch 691/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8161851392.0000 - val_loss: 9821171712.0000\n",
      "Epoch 692/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7924511232.0000 - val_loss: 9344162816.0000\n",
      "Epoch 693/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7943969792.0000 - val_loss: 8798816256.0000\n",
      "Epoch 694/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7927480832.0000 - val_loss: 8487161344.0000\n",
      "Epoch 695/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7972454400.0000 - val_loss: 9357093888.0000\n",
      "Epoch 696/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8070414848.0000 - val_loss: 8654464000.0000\n",
      "Epoch 697/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7810344960.0000 - val_loss: 8502777856.0000\n",
      "Epoch 698/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8219977216.0000 - val_loss: 8586802688.0000\n",
      "Epoch 699/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7779116032.0000 - val_loss: 8964599808.0000\n",
      "Epoch 700/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7922905600.0000 - val_loss: 8736297984.0000\n",
      "Epoch 701/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7847961600.0000 - val_loss: 8978695168.0000\n",
      "Epoch 702/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 8009148928.0000 - val_loss: 8557006848.0000\n",
      "Epoch 703/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7921329664.0000 - val_loss: 8482418688.0000\n",
      "Epoch 704/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7933435392.0000 - val_loss: 8715998208.0000\n",
      "Epoch 705/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8004122624.0000 - val_loss: 8695471104.0000\n",
      "Epoch 706/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8018970112.0000 - val_loss: 8667433984.0000\n",
      "Epoch 707/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8036034048.0000 - val_loss: 8471919616.0000\n",
      "Epoch 708/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7893395456.0000 - val_loss: 8712296448.0000\n",
      "Epoch 709/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7882008064.0000 - val_loss: 9047593984.0000\n",
      "Epoch 710/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7910230016.0000 - val_loss: 8543311360.0000\n",
      "Epoch 711/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7981651456.0000 - val_loss: 8542912000.0000\n",
      "Epoch 712/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7871312896.0000 - val_loss: 8604090368.0000\n",
      "Epoch 713/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8078869504.0000 - val_loss: 8728544256.0000\n",
      "Epoch 714/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7888439808.0000 - val_loss: 8622660608.0000\n",
      "Epoch 715/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7820371968.0000 - val_loss: 8588536320.0000\n",
      "Epoch 716/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8068538368.0000 - val_loss: 8563970048.0000\n",
      "Epoch 717/1500\n",
      "119/119 [==============================] - 0s 957us/step - loss: 8067060736.0000 - val_loss: 9455385600.0000\n",
      "Epoch 718/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7870211072.0000 - val_loss: 8610179072.0000\n",
      "Epoch 719/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8080947712.0000 - val_loss: 8723646464.0000\n",
      "Epoch 720/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8005676544.0000 - val_loss: 9521076224.0000\n",
      "Epoch 721/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7954463744.0000 - val_loss: 8471378944.0000\n",
      "Epoch 722/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7817420800.0000 - val_loss: 8474305024.0000\n",
      "Epoch 723/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7855819776.0000 - val_loss: 8622865408.0000\n",
      "Epoch 724/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 915us/step - loss: 7941069312.0000 - val_loss: 9025911808.0000\n",
      "Epoch 725/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8095791616.0000 - val_loss: 9501606912.0000\n",
      "Epoch 726/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7855808512.0000 - val_loss: 8646056960.0000\n",
      "Epoch 727/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7868987392.0000 - val_loss: 9680772096.0000\n",
      "Epoch 728/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 8143501824.0000 - val_loss: 9086019584.0000\n",
      "Epoch 729/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 8119524864.0000 - val_loss: 8822132736.0000\n",
      "Epoch 730/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8027466752.0000 - val_loss: 8660624384.0000\n",
      "Epoch 731/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7803320832.0000 - val_loss: 8460528640.0000\n",
      "Epoch 732/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7871799808.0000 - val_loss: 9032183808.0000\n",
      "Epoch 733/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8018909696.0000 - val_loss: 8531420160.0000\n",
      "Epoch 734/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8058864640.0000 - val_loss: 8454528512.0000\n",
      "Epoch 735/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7777133056.0000 - val_loss: 8746371072.0000\n",
      "Epoch 736/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7726167040.0000 - val_loss: 8451327488.0000\n",
      "Epoch 737/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7863735296.0000 - val_loss: 8907568128.0000\n",
      "Epoch 738/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7878463488.0000 - val_loss: 8742833152.0000\n",
      "Epoch 739/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7867552256.0000 - val_loss: 8540011520.0000\n",
      "Epoch 740/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7771500032.0000 - val_loss: 8572304384.0000\n",
      "Epoch 741/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7950841856.0000 - val_loss: 8720956416.0000\n",
      "Epoch 742/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7928066048.0000 - val_loss: 8456601088.0000\n",
      "Epoch 743/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7765050368.0000 - val_loss: 8760119296.0000\n",
      "Epoch 744/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8039868928.0000 - val_loss: 8434329088.0000\n",
      "Epoch 745/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7849221632.0000 - val_loss: 9748189184.0000\n",
      "Epoch 746/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7943955968.0000 - val_loss: 8641324032.0000\n",
      "Epoch 747/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7788445184.0000 - val_loss: 8459720704.0000\n",
      "Epoch 748/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7799458304.0000 - val_loss: 8596418560.0000\n",
      "Epoch 749/1500\n",
      "119/119 [==============================] - 0s 894us/step - loss: 7734472704.0000 - val_loss: 8505596928.0000\n",
      "Epoch 750/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7803206144.0000 - val_loss: 8456911872.0000\n",
      "Epoch 751/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8085240832.0000 - val_loss: 8523850752.0000\n",
      "Epoch 752/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7790768128.0000 - val_loss: 8537891840.0000\n",
      "Epoch 753/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7821366272.0000 - val_loss: 8457071104.0000\n",
      "Epoch 754/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7993724928.0000 - val_loss: 8893879296.0000\n",
      "Epoch 755/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7856863744.0000 - val_loss: 8785907712.0000\n",
      "Epoch 756/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8093199360.0000 - val_loss: 9477889024.0000\n",
      "Epoch 757/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8021266432.0000 - val_loss: 8684193792.0000\n",
      "Epoch 758/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7925986304.0000 - val_loss: 8473036800.0000\n",
      "Epoch 759/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7818997760.0000 - val_loss: 8468715008.0000\n",
      "Epoch 760/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7923111936.0000 - val_loss: 9134608384.0000\n",
      "Epoch 761/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 8028312576.0000 - val_loss: 8437365248.0000\n",
      "Epoch 762/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7980940800.0000 - val_loss: 9103340544.0000\n",
      "Epoch 763/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7903200256.0000 - val_loss: 8812891136.0000\n",
      "Epoch 764/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7827765248.0000 - val_loss: 8783597568.0000\n",
      "Epoch 765/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7727413248.0000 - val_loss: 8766182400.0000\n",
      "Epoch 766/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7840571904.0000 - val_loss: 8470288896.0000\n",
      "Epoch 767/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7862474752.0000 - val_loss: 8866843648.0000\n",
      "Epoch 768/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7924209664.0000 - val_loss: 10337003520.0000\n",
      "Epoch 769/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 8210394112.0000 - val_loss: 9316517888.0000\n",
      "Epoch 770/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7879526912.0000 - val_loss: 9699747840.0000\n",
      "Epoch 771/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8265635840.0000 - val_loss: 9466461184.0000\n",
      "Epoch 772/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8114971648.0000 - val_loss: 8560379392.0000\n",
      "Epoch 773/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7788689408.0000 - val_loss: 8439379456.0000\n",
      "Epoch 774/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8153739776.0000 - val_loss: 9462609920.0000\n",
      "Epoch 775/1500\n",
      "119/119 [==============================] - 0s 918us/step - loss: 7785841152.0000 - val_loss: 8459567104.0000\n",
      "Epoch 776/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7763200512.0000 - val_loss: 8548314112.0000\n",
      "Epoch 777/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7813035008.0000 - val_loss: 8428016128.0000\n",
      "Epoch 778/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7891577856.0000 - val_loss: 8442315776.0000\n",
      "Epoch 779/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7874551808.0000 - val_loss: 8567752192.0000\n",
      "Epoch 780/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8170751488.0000 - val_loss: 8494814720.0000\n",
      "Epoch 781/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7793140224.0000 - val_loss: 8927025152.0000\n",
      "Epoch 782/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7932776448.0000 - val_loss: 8596188160.0000\n",
      "Epoch 783/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8040665088.0000 - val_loss: 8444383744.0000\n",
      "Epoch 784/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7876597760.0000 - val_loss: 8635152384.0000\n",
      "Epoch 785/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7929787904.0000 - val_loss: 8506193920.0000\n",
      "Epoch 786/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7739374592.0000 - val_loss: 8733467648.0000\n",
      "Epoch 787/1500\n",
      "119/119 [==============================] - 0s 992us/step - loss: 7915012096.0000 - val_loss: 8429165056.0000\n",
      "Epoch 788/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7708110848.0000 - val_loss: 9138435072.0000\n",
      "Epoch 789/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7890971136.0000 - val_loss: 8672509952.0000\n",
      "Epoch 790/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7913244160.0000 - val_loss: 8625892352.0000\n",
      "Epoch 791/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7850149888.0000 - val_loss: 8526254080.0000\n",
      "Epoch 792/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7754192384.0000 - val_loss: 8388191744.0000\n",
      "Epoch 793/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7800501248.0000 - val_loss: 8592217088.0000\n",
      "Epoch 794/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7792649728.0000 - val_loss: 8422206976.0000\n",
      "Epoch 795/1500\n",
      "119/119 [==============================] - 0s 940us/step - loss: 7798441984.0000 - val_loss: 8403012608.0000\n",
      "Epoch 796/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7917958656.0000 - val_loss: 8534324224.0000\n",
      "Epoch 797/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7934700032.0000 - val_loss: 8421629952.0000\n",
      "Epoch 798/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7825627136.0000 - val_loss: 8461996032.0000\n",
      "Epoch 799/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7731134976.0000 - val_loss: 8514970112.0000\n",
      "Epoch 800/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7757870080.0000 - val_loss: 8462452736.0000\n",
      "Epoch 801/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7841910784.0000 - val_loss: 9960622080.0000\n",
      "Epoch 802/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8012792320.0000 - val_loss: 8611966976.0000\n",
      "Epoch 803/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 8012172288.0000 - val_loss: 8964672512.0000\n",
      "Epoch 804/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7755302400.0000 - val_loss: 8546257408.0000\n",
      "Epoch 805/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7984505856.0000 - val_loss: 8415611904.0000\n",
      "Epoch 806/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7765015552.0000 - val_loss: 8415704064.0000\n",
      "Epoch 807/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7807815680.0000 - val_loss: 8915871744.0000\n",
      "Epoch 808/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7749649408.0000 - val_loss: 8542579712.0000\n",
      "Epoch 809/1500\n",
      "119/119 [==============================] - 0s 894us/step - loss: 7824773632.0000 - val_loss: 8430319616.0000\n",
      "Epoch 810/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7880346624.0000 - val_loss: 8454371840.0000\n",
      "Epoch 811/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8062519808.0000 - val_loss: 8481652736.0000\n",
      "Epoch 812/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7799655424.0000 - val_loss: 8914628608.0000\n",
      "Epoch 813/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7781200384.0000 - val_loss: 8903176192.0000\n",
      "Epoch 814/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7818268160.0000 - val_loss: 8459899392.0000\n",
      "Epoch 815/1500\n",
      "119/119 [==============================] - 0s 992us/step - loss: 7863261184.0000 - val_loss: 8711996416.0000\n",
      "Epoch 816/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8082186752.0000 - val_loss: 8617787392.0000\n",
      "Epoch 817/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7788654592.0000 - val_loss: 9068497920.0000\n",
      "Epoch 818/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7789438464.0000 - val_loss: 8679111680.0000\n",
      "Epoch 819/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7798888960.0000 - val_loss: 8658391040.0000\n",
      "Epoch 820/1500\n",
      "119/119 [==============================] - 0s 923us/step - loss: 7978619392.0000 - val_loss: 8394989056.0000\n",
      "Epoch 821/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7735134720.0000 - val_loss: 8472005632.0000\n",
      "Epoch 822/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7716057600.0000 - val_loss: 8439870464.0000\n",
      "Epoch 823/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7837131776.0000 - val_loss: 8650371072.0000\n",
      "Epoch 824/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7826670080.0000 - val_loss: 8389437952.0000\n",
      "Epoch 825/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7748507648.0000 - val_loss: 8459079168.0000\n",
      "Epoch 826/1500\n",
      "119/119 [==============================] - 0s 914us/step - loss: 7764952576.0000 - val_loss: 8939403264.0000\n",
      "Epoch 827/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7907181568.0000 - val_loss: 8422308864.0000\n",
      "Epoch 828/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7768603648.0000 - val_loss: 8625316864.0000\n",
      "Epoch 829/1500\n",
      "119/119 [==============================] - 0s 923us/step - loss: 7722197504.0000 - val_loss: 8406039552.0000\n",
      "Epoch 830/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7696021504.0000 - val_loss: 8418972672.0000\n",
      "Epoch 831/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7690647040.0000 - val_loss: 9165698048.0000\n",
      "Epoch 832/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8056791040.0000 - val_loss: 8844479488.0000\n",
      "Epoch 833/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7663744000.0000 - val_loss: 8462340096.0000\n",
      "Epoch 834/1500\n",
      "119/119 [==============================] - 0s 916us/step - loss: 7738308096.0000 - val_loss: 8431412736.0000\n",
      "Epoch 835/1500\n",
      "119/119 [==============================] - 0s 914us/step - loss: 7893195776.0000 - val_loss: 9246641152.0000\n",
      "Epoch 836/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7718221824.0000 - val_loss: 8706950144.0000\n",
      "Epoch 837/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7818959872.0000 - val_loss: 8404253696.0000\n",
      "Epoch 838/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7774870016.0000 - val_loss: 8455152640.0000\n",
      "Epoch 839/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7703891456.0000 - val_loss: 9004572672.0000\n",
      "Epoch 840/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7777373696.0000 - val_loss: 8397728256.0000\n",
      "Epoch 841/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7685036544.0000 - val_loss: 8576231424.0000\n",
      "Epoch 842/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7731902464.0000 - val_loss: 8919262208.0000\n",
      "Epoch 843/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7889346560.0000 - val_loss: 8401471488.0000\n",
      "Epoch 844/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 7853605888.0000 - val_loss: 8579175936.0000\n",
      "Epoch 845/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7741522432.0000 - val_loss: 8585491456.0000\n",
      "Epoch 846/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7790289408.0000 - val_loss: 8966981632.0000\n",
      "Epoch 847/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7792743424.0000 - val_loss: 8553937920.0000\n",
      "Epoch 848/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7660989440.0000 - val_loss: 8530634752.0000\n",
      "Epoch 849/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 8158326272.0000 - val_loss: 8636363776.0000\n",
      "Epoch 850/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8075525120.0000 - val_loss: 8442083840.0000\n",
      "Epoch 851/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7670603776.0000 - val_loss: 8584862208.0000\n",
      "Epoch 852/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7873109504.0000 - val_loss: 8791996416.0000\n",
      "Epoch 853/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7709897216.0000 - val_loss: 8775638016.0000\n",
      "Epoch 854/1500\n",
      "119/119 [==============================] - 0s 902us/step - loss: 7775349248.0000 - val_loss: 8382444032.0000\n",
      "Epoch 855/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7726573056.0000 - val_loss: 8575714816.0000\n",
      "Epoch 856/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 924us/step - loss: 7758674432.0000 - val_loss: 9717478400.0000\n",
      "Epoch 857/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7927993856.0000 - val_loss: 8440267264.0000\n",
      "Epoch 858/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7803972096.0000 - val_loss: 8605481984.0000\n",
      "Epoch 859/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7642932736.0000 - val_loss: 8379508736.0000\n",
      "Epoch 860/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7970801152.0000 - val_loss: 8712188928.0000\n",
      "Epoch 861/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 7695992832.0000 - val_loss: 8896599040.0000\n",
      "Epoch 862/1500\n",
      "119/119 [==============================] - 0s 880us/step - loss: 7915768832.0000 - val_loss: 8775883776.0000\n",
      "Epoch 863/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7753371136.0000 - val_loss: 8530094080.0000\n",
      "Epoch 864/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7737526272.0000 - val_loss: 8388009984.0000\n",
      "Epoch 865/1500\n",
      "119/119 [==============================] - 0s 909us/step - loss: 7693063680.0000 - val_loss: 8470718976.0000\n",
      "Epoch 866/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7756579840.0000 - val_loss: 8546014720.0000\n",
      "Epoch 867/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 8161645568.0000 - val_loss: 8615364608.0000\n",
      "Epoch 868/1500\n",
      "119/119 [==============================] - 0s 891us/step - loss: 7775517696.0000 - val_loss: 9728979968.0000\n",
      "Epoch 869/1500\n",
      "119/119 [==============================] - 0s 892us/step - loss: 7838176768.0000 - val_loss: 8645432320.0000\n",
      "Epoch 870/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7770142720.0000 - val_loss: 8504338432.0000\n",
      "Epoch 871/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7595798016.0000 - val_loss: 8386902016.0000\n",
      "Epoch 872/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7629217280.0000 - val_loss: 8464051712.0000\n",
      "Epoch 873/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 7625241600.0000 - val_loss: 8727116800.0000\n",
      "Epoch 874/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 8119120896.0000 - val_loss: 8513885696.0000\n",
      "Epoch 875/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7732433920.0000 - val_loss: 8474803200.0000\n",
      "Epoch 876/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7678732800.0000 - val_loss: 10295277568.0000\n",
      "Epoch 877/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7778030080.0000 - val_loss: 8679142400.0000\n",
      "Epoch 878/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7891944960.0000 - val_loss: 8544131584.0000\n",
      "Epoch 879/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7814240256.0000 - val_loss: 8537914368.0000\n",
      "Epoch 880/1500\n",
      "119/119 [==============================] - 0s 906us/step - loss: 7824775168.0000 - val_loss: 9164227584.0000\n",
      "Epoch 881/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8006770688.0000 - val_loss: 9224744960.0000\n",
      "Epoch 882/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7719776768.0000 - val_loss: 8381262336.0000\n",
      "Epoch 883/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7940399616.0000 - val_loss: 8735016960.0000\n",
      "Epoch 884/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7843021312.0000 - val_loss: 8854663168.0000\n",
      "Epoch 885/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7614862848.0000 - val_loss: 8375864832.0000\n",
      "Epoch 886/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7809324544.0000 - val_loss: 8371141120.0000\n",
      "Epoch 887/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7689583616.0000 - val_loss: 9342116864.0000\n",
      "Epoch 888/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7813498368.0000 - val_loss: 8543018496.0000\n",
      "Epoch 889/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7859389440.0000 - val_loss: 8438416384.0000\n",
      "Epoch 890/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7773499392.0000 - val_loss: 9472115712.0000\n",
      "Epoch 891/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7799236096.0000 - val_loss: 8440623616.0000\n",
      "Epoch 892/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7640957440.0000 - val_loss: 8496331264.0000\n",
      "Epoch 893/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7995579904.0000 - val_loss: 10245651456.0000\n",
      "Epoch 894/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7859990528.0000 - val_loss: 8691756032.0000\n",
      "Epoch 895/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7657356800.0000 - val_loss: 8506352640.0000\n",
      "Epoch 896/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 8066670080.0000 - val_loss: 8335369728.0000\n",
      "Epoch 897/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7742931456.0000 - val_loss: 10168977408.0000\n",
      "Epoch 898/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7757729792.0000 - val_loss: 8591755264.0000\n",
      "Epoch 899/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8146861056.0000 - val_loss: 8710933504.0000\n",
      "Epoch 900/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7739243008.0000 - val_loss: 8473623552.0000\n",
      "Epoch 901/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7746706944.0000 - val_loss: 8464119296.0000\n",
      "Epoch 902/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7687613440.0000 - val_loss: 8464900608.0000\n",
      "Epoch 903/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7829991936.0000 - val_loss: 8544909824.0000\n",
      "Epoch 904/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 8058089472.0000 - val_loss: 8561152512.0000\n",
      "Epoch 905/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7620093952.0000 - val_loss: 8464643584.0000\n",
      "Epoch 906/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7627651584.0000 - val_loss: 8812612608.0000\n",
      "Epoch 907/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7629830144.0000 - val_loss: 8364795904.0000\n",
      "Epoch 908/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7664574464.0000 - val_loss: 8653763584.0000\n",
      "Epoch 909/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7652582912.0000 - val_loss: 8372677120.0000\n",
      "Epoch 910/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7859031040.0000 - val_loss: 8462699008.0000\n",
      "Epoch 911/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7644692992.0000 - val_loss: 8370168320.0000\n",
      "Epoch 912/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7787250176.0000 - val_loss: 8602042368.0000\n",
      "Epoch 913/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7762703360.0000 - val_loss: 8357697536.0000\n",
      "Epoch 914/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7630351360.0000 - val_loss: 8561057792.0000\n",
      "Epoch 915/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7731746304.0000 - val_loss: 8435588096.0000\n",
      "Epoch 916/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7740355584.0000 - val_loss: 8506624000.0000\n",
      "Epoch 917/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7646913536.0000 - val_loss: 8905381888.0000\n",
      "Epoch 918/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7992720896.0000 - val_loss: 8673114112.0000\n",
      "Epoch 919/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7690797056.0000 - val_loss: 8404969472.0000\n",
      "Epoch 920/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7647848448.0000 - val_loss: 8818748416.0000\n",
      "Epoch 921/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7558817280.0000 - val_loss: 8393986560.0000\n",
      "Epoch 922/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7718082048.0000 - val_loss: 9520766976.0000\n",
      "Epoch 923/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7708627968.0000 - val_loss: 8408952832.0000\n",
      "Epoch 924/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7818396160.0000 - val_loss: 8473354752.0000\n",
      "Epoch 925/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7824254464.0000 - val_loss: 10385819648.0000\n",
      "Epoch 926/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7924575744.0000 - val_loss: 8326672384.0000\n",
      "Epoch 927/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7881698304.0000 - val_loss: 8532175360.0000\n",
      "Epoch 928/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7803582976.0000 - val_loss: 8455927808.0000\n",
      "Epoch 929/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7708279296.0000 - val_loss: 8400196096.0000\n",
      "Epoch 930/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7603823104.0000 - val_loss: 8930421760.0000\n",
      "Epoch 931/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7620802560.0000 - val_loss: 8388278272.0000\n",
      "Epoch 932/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7611548160.0000 - val_loss: 8468096512.0000\n",
      "Epoch 933/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7744519168.0000 - val_loss: 8633080832.0000\n",
      "Epoch 934/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7691054592.0000 - val_loss: 8856121344.0000\n",
      "Epoch 935/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7701454848.0000 - val_loss: 8884651008.0000\n",
      "Epoch 936/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7612418560.0000 - val_loss: 8310867968.0000\n",
      "Epoch 937/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7661940736.0000 - val_loss: 9626377216.0000\n",
      "Epoch 938/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7598823424.0000 - val_loss: 9985160192.0000\n",
      "Epoch 939/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7662411776.0000 - val_loss: 8382040064.0000\n",
      "Epoch 940/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7614759424.0000 - val_loss: 8397177856.0000\n",
      "Epoch 941/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7677401088.0000 - val_loss: 8542205440.0000\n",
      "Epoch 942/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7691741184.0000 - val_loss: 8388978176.0000\n",
      "Epoch 943/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 8185964544.0000 - val_loss: 8467945984.0000\n",
      "Epoch 944/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7855368704.0000 - val_loss: 8742752256.0000\n",
      "Epoch 945/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7630147072.0000 - val_loss: 8460811264.0000\n",
      "Epoch 946/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7721444864.0000 - val_loss: 8700870656.0000\n",
      "Epoch 947/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7850400256.0000 - val_loss: 8389576192.0000\n",
      "Epoch 948/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7669768704.0000 - val_loss: 8568111616.0000\n",
      "Epoch 949/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7653481472.0000 - val_loss: 8342249984.0000\n",
      "Epoch 950/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7760191488.0000 - val_loss: 8588369920.0000\n",
      "Epoch 951/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7814550016.0000 - val_loss: 8290390016.0000\n",
      "Epoch 952/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7723170304.0000 - val_loss: 8472059904.0000\n",
      "Epoch 953/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7783236608.0000 - val_loss: 8393999360.0000\n",
      "Epoch 954/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7706612224.0000 - val_loss: 8483600896.0000\n",
      "Epoch 955/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7861476864.0000 - val_loss: 9478692864.0000\n",
      "Epoch 956/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7824301056.0000 - val_loss: 8312988672.0000\n",
      "Epoch 957/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7881001984.0000 - val_loss: 8997236736.0000\n",
      "Epoch 958/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7748612608.0000 - val_loss: 8674970624.0000\n",
      "Epoch 959/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7621163008.0000 - val_loss: 8354207232.0000\n",
      "Epoch 960/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7682770944.0000 - val_loss: 8471691264.0000\n",
      "Epoch 961/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7613648896.0000 - val_loss: 8388506112.0000\n",
      "Epoch 962/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7781278720.0000 - val_loss: 8398353920.0000\n",
      "Epoch 963/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7644492288.0000 - val_loss: 8327873024.0000\n",
      "Epoch 964/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7570643456.0000 - val_loss: 8324116480.0000\n",
      "Epoch 965/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7751904256.0000 - val_loss: 8866383872.0000\n",
      "Epoch 966/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7613704704.0000 - val_loss: 8327027712.0000\n",
      "Epoch 967/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7652227072.0000 - val_loss: 8454613504.0000\n",
      "Epoch 968/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7600518656.0000 - val_loss: 8365672448.0000\n",
      "Epoch 969/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7702614528.0000 - val_loss: 8741112832.0000\n",
      "Epoch 970/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7724495360.0000 - val_loss: 8367220736.0000\n",
      "Epoch 971/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7630737920.0000 - val_loss: 10055533568.0000\n",
      "Epoch 972/1500\n",
      "119/119 [==============================] - 0s 975us/step - loss: 8041887744.0000 - val_loss: 8831132672.0000\n",
      "Epoch 973/1500\n",
      "119/119 [==============================] - 0s 975us/step - loss: 7761762816.0000 - val_loss: 8866120704.0000\n",
      "Epoch 974/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7662466048.0000 - val_loss: 8405779456.0000\n",
      "Epoch 975/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7646971392.0000 - val_loss: 9053735936.0000\n",
      "Epoch 976/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7702803456.0000 - val_loss: 8318289408.0000\n",
      "Epoch 977/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7569702912.0000 - val_loss: 8307139072.0000\n",
      "Epoch 978/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7765798400.0000 - val_loss: 8713708544.0000\n",
      "Epoch 979/1500\n",
      "119/119 [==============================] - 0s 920us/step - loss: 7678295552.0000 - val_loss: 8388088832.0000\n",
      "Epoch 980/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7552848896.0000 - val_loss: 8374167552.0000\n",
      "Epoch 981/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7654928896.0000 - val_loss: 8668059648.0000\n",
      "Epoch 982/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7828305920.0000 - val_loss: 8349916672.0000\n",
      "Epoch 983/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7718209024.0000 - val_loss: 8356765696.0000\n",
      "Epoch 984/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7783878144.0000 - val_loss: 8516907520.0000\n",
      "Epoch 985/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7597571072.0000 - val_loss: 8334945280.0000\n",
      "Epoch 986/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7582765056.0000 - val_loss: 8667012096.0000\n",
      "Epoch 987/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7802788864.0000 - val_loss: 9631974400.0000\n",
      "Epoch 988/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 932us/step - loss: 7642101248.0000 - val_loss: 8381873152.0000\n",
      "Epoch 989/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7651625984.0000 - val_loss: 8367937024.0000\n",
      "Epoch 990/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7640488960.0000 - val_loss: 8564531200.0000\n",
      "Epoch 991/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7916409856.0000 - val_loss: 9868774400.0000\n",
      "Epoch 992/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7675005440.0000 - val_loss: 8502346752.0000\n",
      "Epoch 993/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7573843968.0000 - val_loss: 8367115264.0000\n",
      "Epoch 994/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7723092480.0000 - val_loss: 8287999488.0000\n",
      "Epoch 995/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7642644480.0000 - val_loss: 8347116544.0000\n",
      "Epoch 996/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7623443456.0000 - val_loss: 8824288256.0000\n",
      "Epoch 997/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7691748864.0000 - val_loss: 8653859840.0000\n",
      "Epoch 998/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7844686848.0000 - val_loss: 8383108608.0000\n",
      "Epoch 999/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7706195968.0000 - val_loss: 8363177984.0000\n",
      "Epoch 1000/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7723082240.0000 - val_loss: 9545936896.0000\n",
      "Epoch 1001/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8081349632.0000 - val_loss: 8392806912.0000\n",
      "Epoch 1002/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7643336704.0000 - val_loss: 8312660480.0000\n",
      "Epoch 1003/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7669178368.0000 - val_loss: 8302886912.0000\n",
      "Epoch 1004/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7723653632.0000 - val_loss: 8299215872.0000\n",
      "Epoch 1005/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7690043904.0000 - val_loss: 8661117952.0000\n",
      "Epoch 1006/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7609599488.0000 - val_loss: 8495411712.0000\n",
      "Epoch 1007/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7539023360.0000 - val_loss: 8688549888.0000\n",
      "Epoch 1008/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7600946688.0000 - val_loss: 8539026432.0000\n",
      "Epoch 1009/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7800341504.0000 - val_loss: 9507895296.0000\n",
      "Epoch 1010/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7751894016.0000 - val_loss: 8394644480.0000\n",
      "Epoch 1011/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7595988480.0000 - val_loss: 8274040832.0000\n",
      "Epoch 1012/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7728374784.0000 - val_loss: 8352848896.0000\n",
      "Epoch 1013/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7659356160.0000 - val_loss: 8541258752.0000\n",
      "Epoch 1014/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7702376448.0000 - val_loss: 8251227136.0000\n",
      "Epoch 1015/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7757557760.0000 - val_loss: 8312441344.0000\n",
      "Epoch 1016/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7607070720.0000 - val_loss: 8454399488.0000\n",
      "Epoch 1017/1500\n",
      "119/119 [==============================] - 0s 966us/step - loss: 7507517440.0000 - val_loss: 8309607424.0000\n",
      "Epoch 1018/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7563436032.0000 - val_loss: 8663999488.0000\n",
      "Epoch 1019/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7640846336.0000 - val_loss: 8885593088.0000\n",
      "Epoch 1020/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7812339200.0000 - val_loss: 8381843456.0000\n",
      "Epoch 1021/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7609630208.0000 - val_loss: 8619214848.0000\n",
      "Epoch 1022/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7728885760.0000 - val_loss: 8444705280.0000\n",
      "Epoch 1023/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7633966592.0000 - val_loss: 8382264320.0000\n",
      "Epoch 1024/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7555151360.0000 - val_loss: 8302804480.0000\n",
      "Epoch 1025/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7632500736.0000 - val_loss: 9194151936.0000\n",
      "Epoch 1026/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7620117504.0000 - val_loss: 8414249472.0000\n",
      "Epoch 1027/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7750668800.0000 - val_loss: 8350272000.0000\n",
      "Epoch 1028/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7659980800.0000 - val_loss: 8312803840.0000\n",
      "Epoch 1029/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7725632512.0000 - val_loss: 8314277888.0000\n",
      "Epoch 1030/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7688274944.0000 - val_loss: 8538800640.0000\n",
      "Epoch 1031/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7566394368.0000 - val_loss: 8532575232.0000\n",
      "Epoch 1032/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7573443584.0000 - val_loss: 8264365568.0000\n",
      "Epoch 1033/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7694277632.0000 - val_loss: 8384673792.0000\n",
      "Epoch 1034/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7859941376.0000 - val_loss: 9002314752.0000\n",
      "Epoch 1035/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7843431424.0000 - val_loss: 8331659776.0000\n",
      "Epoch 1036/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 8019460096.0000 - val_loss: 9196080128.0000\n",
      "Epoch 1037/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7761426944.0000 - val_loss: 9070458880.0000\n",
      "Epoch 1038/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7582383616.0000 - val_loss: 8852631552.0000\n",
      "Epoch 1039/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7661105152.0000 - val_loss: 8356205056.0000\n",
      "Epoch 1040/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7524022272.0000 - val_loss: 8838246400.0000\n",
      "Epoch 1041/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7983272448.0000 - val_loss: 9020157952.0000\n",
      "Epoch 1042/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7707352576.0000 - val_loss: 8294030336.0000\n",
      "Epoch 1043/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7865029632.0000 - val_loss: 9422911488.0000\n",
      "Epoch 1044/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7648560640.0000 - val_loss: 8604432384.0000\n",
      "Epoch 1045/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7743479808.0000 - val_loss: 8576555008.0000\n",
      "Epoch 1046/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7562311168.0000 - val_loss: 8453648384.0000\n",
      "Epoch 1047/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7595376128.0000 - val_loss: 8826207232.0000\n",
      "Epoch 1048/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7680034816.0000 - val_loss: 8838384640.0000\n",
      "Epoch 1049/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7628099072.0000 - val_loss: 8484995584.0000\n",
      "Epoch 1050/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7629966336.0000 - val_loss: 9069720576.0000\n",
      "Epoch 1051/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7886110720.0000 - val_loss: 8388340736.0000\n",
      "Epoch 1052/1500\n",
      "119/119 [==============================] - 0s 930us/step - loss: 7591835648.0000 - val_loss: 8278985728.0000\n",
      "Epoch 1053/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7592262656.0000 - val_loss: 8319574528.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1054/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7648416256.0000 - val_loss: 8402789888.0000\n",
      "Epoch 1055/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7765453824.0000 - val_loss: 8760378368.0000\n",
      "Epoch 1056/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7580728832.0000 - val_loss: 8310127616.0000\n",
      "Epoch 1057/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7582121472.0000 - val_loss: 8300337152.0000\n",
      "Epoch 1058/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7735949824.0000 - val_loss: 8619939840.0000\n",
      "Epoch 1059/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7473017344.0000 - val_loss: 8343745024.0000\n",
      "Epoch 1060/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 8064081408.0000 - val_loss: 8514418176.0000\n",
      "Epoch 1061/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7540172800.0000 - val_loss: 8764641280.0000\n",
      "Epoch 1062/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7603948032.0000 - val_loss: 8308550656.0000\n",
      "Epoch 1063/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7706231296.0000 - val_loss: 8475522560.0000\n",
      "Epoch 1064/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7530172416.0000 - val_loss: 8371330560.0000\n",
      "Epoch 1065/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7627908096.0000 - val_loss: 8342599168.0000\n",
      "Epoch 1066/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7745737216.0000 - val_loss: 8745545728.0000\n",
      "Epoch 1067/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7655629824.0000 - val_loss: 9496679424.0000\n",
      "Epoch 1068/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7666031616.0000 - val_loss: 8704906240.0000\n",
      "Epoch 1069/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7520425984.0000 - val_loss: 8292111360.0000\n",
      "Epoch 1070/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7539369984.0000 - val_loss: 8420013056.0000\n",
      "Epoch 1071/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7553602560.0000 - val_loss: 8271076352.0000\n",
      "Epoch 1072/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7740886016.0000 - val_loss: 8511223296.0000\n",
      "Epoch 1073/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7897878528.0000 - val_loss: 9923525632.0000\n",
      "Epoch 1074/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7668261888.0000 - val_loss: 8301127680.0000\n",
      "Epoch 1075/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7650429440.0000 - val_loss: 8343079936.0000\n",
      "Epoch 1076/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7533966336.0000 - val_loss: 8391539712.0000\n",
      "Epoch 1077/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7781816320.0000 - val_loss: 8412879360.0000\n",
      "Epoch 1078/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7546834432.0000 - val_loss: 9742064640.0000\n",
      "Epoch 1079/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7691024384.0000 - val_loss: 9611104256.0000\n",
      "Epoch 1080/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7801805312.0000 - val_loss: 9085596672.0000\n",
      "Epoch 1081/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7746435072.0000 - val_loss: 8402854400.0000\n",
      "Epoch 1082/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7540701184.0000 - val_loss: 8418006016.0000\n",
      "Epoch 1083/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7632641024.0000 - val_loss: 8319004672.0000\n",
      "Epoch 1084/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7450222080.0000 - val_loss: 8365778944.0000\n",
      "Epoch 1085/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7626117632.0000 - val_loss: 8261231104.0000\n",
      "Epoch 1086/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7594074112.0000 - val_loss: 9444408320.0000\n",
      "Epoch 1087/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7598395392.0000 - val_loss: 8279910400.0000\n",
      "Epoch 1088/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7523171840.0000 - val_loss: 8482934784.0000\n",
      "Epoch 1089/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7523458560.0000 - val_loss: 8361395200.0000\n",
      "Epoch 1090/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7699263488.0000 - val_loss: 9225949184.0000\n",
      "Epoch 1091/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7775049216.0000 - val_loss: 8911924224.0000\n",
      "Epoch 1092/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7669607936.0000 - val_loss: 8784077824.0000\n",
      "Epoch 1093/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7717719552.0000 - val_loss: 8437698048.0000\n",
      "Epoch 1094/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7626711552.0000 - val_loss: 8313874944.0000\n",
      "Epoch 1095/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7504860672.0000 - val_loss: 8331596288.0000\n",
      "Epoch 1096/1500\n",
      "119/119 [==============================] - 0s 886us/step - loss: 7727451136.0000 - val_loss: 8285240320.0000\n",
      "Epoch 1097/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7581726208.0000 - val_loss: 8278965760.0000\n",
      "Epoch 1098/1500\n",
      "119/119 [==============================] - 0s 905us/step - loss: 7799847424.0000 - val_loss: 8334008320.0000\n",
      "Epoch 1099/1500\n",
      "119/119 [==============================] - 0s 886us/step - loss: 7607785984.0000 - val_loss: 9040047104.0000\n",
      "Epoch 1100/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7515237376.0000 - val_loss: 8241740800.0000\n",
      "Epoch 1101/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7553725952.0000 - val_loss: 8840287232.0000\n",
      "Epoch 1102/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7617567232.0000 - val_loss: 8843634688.0000\n",
      "Epoch 1103/1500\n",
      "119/119 [==============================] - 0s 910us/step - loss: 7725690368.0000 - val_loss: 8299746304.0000\n",
      "Epoch 1104/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7602069504.0000 - val_loss: 9298601984.0000\n",
      "Epoch 1105/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7512988160.0000 - val_loss: 8607234048.0000\n",
      "Epoch 1106/1500\n",
      "119/119 [==============================] - 0s 919us/step - loss: 7632046080.0000 - val_loss: 8567070720.0000\n",
      "Epoch 1107/1500\n",
      "119/119 [==============================] - 0s 911us/step - loss: 7641647616.0000 - val_loss: 8381081088.0000\n",
      "Epoch 1108/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7467825152.0000 - val_loss: 8291324416.0000\n",
      "Epoch 1109/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7746868224.0000 - val_loss: 9806822400.0000\n",
      "Epoch 1110/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7543324160.0000 - val_loss: 8339204096.0000\n",
      "Epoch 1111/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7937617408.0000 - val_loss: 8268335104.0000\n",
      "Epoch 1112/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7544011264.0000 - val_loss: 8214521344.0000\n",
      "Epoch 1113/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7676585984.0000 - val_loss: 8304857088.0000\n",
      "Epoch 1114/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7588182528.0000 - val_loss: 8390093312.0000\n",
      "Epoch 1115/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7628393472.0000 - val_loss: 8409393152.0000\n",
      "Epoch 1116/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7465067520.0000 - val_loss: 8454892544.0000\n",
      "Epoch 1117/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7603023872.0000 - val_loss: 8265705472.0000\n",
      "Epoch 1118/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7630967808.0000 - val_loss: 8216958464.0000\n",
      "Epoch 1119/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7739569664.0000 - val_loss: 8267524096.0000\n",
      "Epoch 1120/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7760303616.0000 - val_loss: 8436774400.0000\n",
      "Epoch 1121/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7641466368.0000 - val_loss: 8379356160.0000\n",
      "Epoch 1122/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7501112832.0000 - val_loss: 8326571520.0000\n",
      "Epoch 1123/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7930777600.0000 - val_loss: 8269749760.0000\n",
      "Epoch 1124/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7606227456.0000 - val_loss: 8473900032.0000\n",
      "Epoch 1125/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7479069184.0000 - val_loss: 8751843328.0000\n",
      "Epoch 1126/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7523629568.0000 - val_loss: 8358379520.0000\n",
      "Epoch 1127/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7468388352.0000 - val_loss: 8933176320.0000\n",
      "Epoch 1128/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7770030592.0000 - val_loss: 8226305024.0000\n",
      "Epoch 1129/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7518373888.0000 - val_loss: 8240647168.0000\n",
      "Epoch 1130/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7478832640.0000 - val_loss: 8953154560.0000\n",
      "Epoch 1131/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7560313344.0000 - val_loss: 8347580928.0000\n",
      "Epoch 1132/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7646207488.0000 - val_loss: 9571435520.0000\n",
      "Epoch 1133/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7715501056.0000 - val_loss: 9169220608.0000\n",
      "Epoch 1134/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7574343168.0000 - val_loss: 8220760576.0000\n",
      "Epoch 1135/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7450025472.0000 - val_loss: 8555593728.0000\n",
      "Epoch 1136/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7585498624.0000 - val_loss: 8264934912.0000\n",
      "Epoch 1137/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7721883648.0000 - val_loss: 8303831552.0000\n",
      "Epoch 1138/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7643215872.0000 - val_loss: 8389758976.0000\n",
      "Epoch 1139/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7540077568.0000 - val_loss: 8598298624.0000\n",
      "Epoch 1140/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7497532416.0000 - val_loss: 8287347200.0000\n",
      "Epoch 1141/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7576868352.0000 - val_loss: 8647311360.0000\n",
      "Epoch 1142/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7547722752.0000 - val_loss: 8237742592.0000\n",
      "Epoch 1143/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7630796800.0000 - val_loss: 8525721600.0000\n",
      "Epoch 1144/1500\n",
      "119/119 [==============================] - 0s 903us/step - loss: 7548937216.0000 - val_loss: 8259588608.0000\n",
      "Epoch 1145/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7681028608.0000 - val_loss: 8368346112.0000\n",
      "Epoch 1146/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7608870400.0000 - val_loss: 8241818624.0000\n",
      "Epoch 1147/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7537222656.0000 - val_loss: 8393740800.0000\n",
      "Epoch 1148/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7674890752.0000 - val_loss: 8244012032.0000\n",
      "Epoch 1149/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7428708864.0000 - val_loss: 8208297984.0000\n",
      "Epoch 1150/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7530774016.0000 - val_loss: 8258904576.0000\n",
      "Epoch 1151/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7709340672.0000 - val_loss: 8255381504.0000\n",
      "Epoch 1152/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7588958208.0000 - val_loss: 10307145728.0000\n",
      "Epoch 1153/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7769899520.0000 - val_loss: 8313182720.0000\n",
      "Epoch 1154/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7494233088.0000 - val_loss: 10127702016.0000\n",
      "Epoch 1155/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7473584640.0000 - val_loss: 8254352384.0000\n",
      "Epoch 1156/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7502273536.0000 - val_loss: 8210890240.0000\n",
      "Epoch 1157/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7605069824.0000 - val_loss: 8548509184.0000\n",
      "Epoch 1158/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7501387776.0000 - val_loss: 8295919616.0000\n",
      "Epoch 1159/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7557902848.0000 - val_loss: 8776698880.0000\n",
      "Epoch 1160/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7491481600.0000 - val_loss: 8407737344.0000\n",
      "Epoch 1161/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7558087168.0000 - val_loss: 9072516096.0000\n",
      "Epoch 1162/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7422045696.0000 - val_loss: 8356816896.0000\n",
      "Epoch 1163/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7446342144.0000 - val_loss: 8314362880.0000\n",
      "Epoch 1164/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7420946944.0000 - val_loss: 8562726400.0000\n",
      "Epoch 1165/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7856180736.0000 - val_loss: 8452742144.0000\n",
      "Epoch 1166/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7457493504.0000 - val_loss: 9233828864.0000\n",
      "Epoch 1167/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7595641856.0000 - val_loss: 8482195456.0000\n",
      "Epoch 1168/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7613961216.0000 - val_loss: 8339566592.0000\n",
      "Epoch 1169/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7533596672.0000 - val_loss: 8241473024.0000\n",
      "Epoch 1170/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7518231552.0000 - val_loss: 8315202048.0000\n",
      "Epoch 1171/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7519811584.0000 - val_loss: 9323668480.0000\n",
      "Epoch 1172/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7490874880.0000 - val_loss: 8506733568.0000\n",
      "Epoch 1173/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7975820800.0000 - val_loss: 9285781504.0000\n",
      "Epoch 1174/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7502770688.0000 - val_loss: 8948632576.0000\n",
      "Epoch 1175/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7498891264.0000 - val_loss: 8305994240.0000\n",
      "Epoch 1176/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7695234048.0000 - val_loss: 8605189120.0000\n",
      "Epoch 1177/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7516026880.0000 - val_loss: 8318752256.0000\n",
      "Epoch 1178/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7529971712.0000 - val_loss: 8271363584.0000\n",
      "Epoch 1179/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7706379776.0000 - val_loss: 8208009216.0000\n",
      "Epoch 1180/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7531506176.0000 - val_loss: 8240651776.0000\n",
      "Epoch 1181/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7593518080.0000 - val_loss: 8238818816.0000\n",
      "Epoch 1182/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7457817600.0000 - val_loss: 8551960064.0000\n",
      "Epoch 1183/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7514183168.0000 - val_loss: 8225354752.0000\n",
      "Epoch 1184/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 907us/step - loss: 7552054272.0000 - val_loss: 8914244608.0000\n",
      "Epoch 1185/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7634262016.0000 - val_loss: 8329146880.0000\n",
      "Epoch 1186/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7539668480.0000 - val_loss: 8706607104.0000\n",
      "Epoch 1187/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7467780608.0000 - val_loss: 8219143168.0000\n",
      "Epoch 1188/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7482017792.0000 - val_loss: 8474461184.0000\n",
      "Epoch 1189/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7758200832.0000 - val_loss: 8275951104.0000\n",
      "Epoch 1190/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7458494464.0000 - val_loss: 8280114176.0000\n",
      "Epoch 1191/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7542909440.0000 - val_loss: 8744323072.0000\n",
      "Epoch 1192/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7528490496.0000 - val_loss: 8300366848.0000\n",
      "Epoch 1193/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7812307456.0000 - val_loss: 8591475712.0000\n",
      "Epoch 1194/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7459955200.0000 - val_loss: 8404823552.0000\n",
      "Epoch 1195/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7492862464.0000 - val_loss: 8356259328.0000\n",
      "Epoch 1196/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7573726720.0000 - val_loss: 8251435520.0000\n",
      "Epoch 1197/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7861611520.0000 - val_loss: 9593804800.0000\n",
      "Epoch 1198/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7444013056.0000 - val_loss: 8470503936.0000\n",
      "Epoch 1199/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7606963712.0000 - val_loss: 8438677504.0000\n",
      "Epoch 1200/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7522504704.0000 - val_loss: 8251525632.0000\n",
      "Epoch 1201/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7572756480.0000 - val_loss: 8826145792.0000\n",
      "Epoch 1202/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7740790784.0000 - val_loss: 8226632192.0000\n",
      "Epoch 1203/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7421520896.0000 - val_loss: 8532012544.0000\n",
      "Epoch 1204/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7707628032.0000 - val_loss: 8274307584.0000\n",
      "Epoch 1205/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7539671552.0000 - val_loss: 8586480640.0000\n",
      "Epoch 1206/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7485113856.0000 - val_loss: 8216378368.0000\n",
      "Epoch 1207/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7443305984.0000 - val_loss: 8210663424.0000\n",
      "Epoch 1208/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7543754240.0000 - val_loss: 8271070720.0000\n",
      "Epoch 1209/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7439074304.0000 - val_loss: 8255593984.0000\n",
      "Epoch 1210/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7515706368.0000 - val_loss: 8465900544.0000\n",
      "Epoch 1211/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7450974720.0000 - val_loss: 8317664768.0000\n",
      "Epoch 1212/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7568323584.0000 - val_loss: 8321983488.0000\n",
      "Epoch 1213/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7425366528.0000 - val_loss: 8319137792.0000\n",
      "Epoch 1214/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7552187904.0000 - val_loss: 8392012800.0000\n",
      "Epoch 1215/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7718006784.0000 - val_loss: 8235137536.0000\n",
      "Epoch 1216/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7437573632.0000 - val_loss: 8426427392.0000\n",
      "Epoch 1217/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7478607872.0000 - val_loss: 8280171008.0000\n",
      "Epoch 1218/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7746247680.0000 - val_loss: 8557742592.0000\n",
      "Epoch 1219/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7525060608.0000 - val_loss: 8308781056.0000\n",
      "Epoch 1220/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7621852160.0000 - val_loss: 8336288768.0000\n",
      "Epoch 1221/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7466831360.0000 - val_loss: 8335095808.0000\n",
      "Epoch 1222/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7612598784.0000 - val_loss: 8240164352.0000\n",
      "Epoch 1223/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7483302400.0000 - val_loss: 8158103552.0000\n",
      "Epoch 1224/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7602751488.0000 - val_loss: 8478532096.0000\n",
      "Epoch 1225/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7748964352.0000 - val_loss: 8960079872.0000\n",
      "Epoch 1226/1500\n",
      "119/119 [==============================] - 0s 916us/step - loss: 7629645312.0000 - val_loss: 8187835392.0000\n",
      "Epoch 1227/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7371150336.0000 - val_loss: 8191378432.0000\n",
      "Epoch 1228/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7538533376.0000 - val_loss: 8588580352.0000\n",
      "Epoch 1229/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7596686848.0000 - val_loss: 8220466688.0000\n",
      "Epoch 1230/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7565629440.0000 - val_loss: 8964254720.0000\n",
      "Epoch 1231/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7546795520.0000 - val_loss: 8304161792.0000\n",
      "Epoch 1232/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7615519232.0000 - val_loss: 8228099072.0000\n",
      "Epoch 1233/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7401316352.0000 - val_loss: 8194115584.0000\n",
      "Epoch 1234/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7495963648.0000 - val_loss: 8239556608.0000\n",
      "Epoch 1235/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7336969728.0000 - val_loss: 8243913216.0000\n",
      "Epoch 1236/1500\n",
      "119/119 [==============================] - 0s 891us/step - loss: 7449177600.0000 - val_loss: 8236335616.0000\n",
      "Epoch 1237/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7543771648.0000 - val_loss: 8184761856.0000\n",
      "Epoch 1238/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7511926272.0000 - val_loss: 8201188352.0000\n",
      "Epoch 1239/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7417927168.0000 - val_loss: 8190044160.0000\n",
      "Epoch 1240/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7494101504.0000 - val_loss: 8352155648.0000\n",
      "Epoch 1241/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7725778944.0000 - val_loss: 9440309248.0000\n",
      "Epoch 1242/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7518897152.0000 - val_loss: 8190102016.0000\n",
      "Epoch 1243/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7528984064.0000 - val_loss: 8219796992.0000\n",
      "Epoch 1244/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7424779776.0000 - val_loss: 8237292544.0000\n",
      "Epoch 1245/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7469522944.0000 - val_loss: 8220713984.0000\n",
      "Epoch 1246/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7468334080.0000 - val_loss: 8802874368.0000\n",
      "Epoch 1247/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7462080512.0000 - val_loss: 8303058944.0000\n",
      "Epoch 1248/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7536083456.0000 - val_loss: 9839628288.0000\n",
      "Epoch 1249/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7544360448.0000 - val_loss: 8506758656.0000\n",
      "Epoch 1250/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7589182976.0000 - val_loss: 8276924928.0000\n",
      "Epoch 1251/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7417863680.0000 - val_loss: 8658262016.0000\n",
      "Epoch 1252/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7429580288.0000 - val_loss: 8207011840.0000\n",
      "Epoch 1253/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7688670720.0000 - val_loss: 8757062656.0000\n",
      "Epoch 1254/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7468689920.0000 - val_loss: 8239541760.0000\n",
      "Epoch 1255/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7439267328.0000 - val_loss: 8741972992.0000\n",
      "Epoch 1256/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7664497664.0000 - val_loss: 8658829312.0000\n",
      "Epoch 1257/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7380754944.0000 - val_loss: 8227264000.0000\n",
      "Epoch 1258/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7790338560.0000 - val_loss: 8186962944.0000\n",
      "Epoch 1259/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7711764992.0000 - val_loss: 8180943872.0000\n",
      "Epoch 1260/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7484298240.0000 - val_loss: 9304127488.0000\n",
      "Epoch 1261/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7421070336.0000 - val_loss: 8428540416.0000\n",
      "Epoch 1262/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7441624064.0000 - val_loss: 8489581056.0000\n",
      "Epoch 1263/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7328154624.0000 - val_loss: 8619688960.0000\n",
      "Epoch 1264/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7536803328.0000 - val_loss: 8178386944.0000\n",
      "Epoch 1265/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7600876032.0000 - val_loss: 8511966720.0000\n",
      "Epoch 1266/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7367141376.0000 - val_loss: 8164455424.0000\n",
      "Epoch 1267/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7532316672.0000 - val_loss: 9485528064.0000\n",
      "Epoch 1268/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7905970176.0000 - val_loss: 8260654080.0000\n",
      "Epoch 1269/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7402772992.0000 - val_loss: 8708712448.0000\n",
      "Epoch 1270/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7410579968.0000 - val_loss: 8979429376.0000\n",
      "Epoch 1271/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7664633344.0000 - val_loss: 8200268288.0000\n",
      "Epoch 1272/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7479914496.0000 - val_loss: 8173085696.0000\n",
      "Epoch 1273/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 7485650432.0000 - val_loss: 8615929856.0000\n",
      "Epoch 1274/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7592071680.0000 - val_loss: 8309557760.0000\n",
      "Epoch 1275/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7473987072.0000 - val_loss: 8156149760.0000\n",
      "Epoch 1276/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7558258176.0000 - val_loss: 8280448000.0000\n",
      "Epoch 1277/1500\n",
      "119/119 [==============================] - 0s 983us/step - loss: 7361551360.0000 - val_loss: 9003451392.0000\n",
      "Epoch 1278/1500\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 7500354048.0000 - val_loss: 8902481920.0000\n",
      "Epoch 1279/1500\n",
      "119/119 [==============================] - 0s 975us/step - loss: 7421017088.0000 - val_loss: 8709554176.0000\n",
      "Epoch 1280/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7448069120.0000 - val_loss: 8245958144.0000\n",
      "Epoch 1281/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7554816512.0000 - val_loss: 8355844096.0000\n",
      "Epoch 1282/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 7493507584.0000 - val_loss: 9308100608.0000\n",
      "Epoch 1283/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7434482688.0000 - val_loss: 8324902400.0000\n",
      "Epoch 1284/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7550647808.0000 - val_loss: 8303152640.0000\n",
      "Epoch 1285/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7542038528.0000 - val_loss: 8491969536.0000\n",
      "Epoch 1286/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7654149632.0000 - val_loss: 8304644096.0000\n",
      "Epoch 1287/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7398548992.0000 - val_loss: 8411849216.0000\n",
      "Epoch 1288/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7431932928.0000 - val_loss: 8276569600.0000\n",
      "Epoch 1289/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7664866816.0000 - val_loss: 8300412416.0000\n",
      "Epoch 1290/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7540492800.0000 - val_loss: 8305666048.0000\n",
      "Epoch 1291/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7688930304.0000 - val_loss: 8322118144.0000\n",
      "Epoch 1292/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7453451264.0000 - val_loss: 8165170176.0000\n",
      "Epoch 1293/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7508870656.0000 - val_loss: 8281058816.0000\n",
      "Epoch 1294/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7366413312.0000 - val_loss: 8190792704.0000\n",
      "Epoch 1295/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7801898496.0000 - val_loss: 8731091968.0000\n",
      "Epoch 1296/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7523486208.0000 - val_loss: 8709673984.0000\n",
      "Epoch 1297/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7433918976.0000 - val_loss: 8726301696.0000\n",
      "Epoch 1298/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7359453696.0000 - val_loss: 8231656960.0000\n",
      "Epoch 1299/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7529876992.0000 - val_loss: 8356071424.0000\n",
      "Epoch 1300/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7367229440.0000 - val_loss: 8481566208.0000\n",
      "Epoch 1301/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7710122496.0000 - val_loss: 8215921664.0000\n",
      "Epoch 1302/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7393613824.0000 - val_loss: 8164578304.0000\n",
      "Epoch 1303/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7571300864.0000 - val_loss: 8213921792.0000\n",
      "Epoch 1304/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7459521024.0000 - val_loss: 8686559232.0000\n",
      "Epoch 1305/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7380809216.0000 - val_loss: 8346286080.0000\n",
      "Epoch 1306/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7441187328.0000 - val_loss: 8256517120.0000\n",
      "Epoch 1307/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7350307328.0000 - val_loss: 9263442944.0000\n",
      "Epoch 1308/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7616964096.0000 - val_loss: 8900842496.0000\n",
      "Epoch 1309/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7541222400.0000 - val_loss: 8841517056.0000\n",
      "Epoch 1310/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7551586304.0000 - val_loss: 8531855872.0000\n",
      "Epoch 1311/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 7402789376.0000 - val_loss: 8205437952.0000\n",
      "Epoch 1312/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7398106112.0000 - val_loss: 8478073344.0000\n",
      "Epoch 1313/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7509893120.0000 - val_loss: 8132218880.0000\n",
      "Epoch 1314/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 932us/step - loss: 7564465664.0000 - val_loss: 8223506432.0000\n",
      "Epoch 1315/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7355409408.0000 - val_loss: 8334928896.0000\n",
      "Epoch 1316/1500\n",
      "119/119 [==============================] - 0s 908us/step - loss: 7492904448.0000 - val_loss: 8219943936.0000\n",
      "Epoch 1317/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7538353664.0000 - val_loss: 8248207872.0000\n",
      "Epoch 1318/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7545575936.0000 - val_loss: 8180801024.0000\n",
      "Epoch 1319/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7465430016.0000 - val_loss: 8154198528.0000\n",
      "Epoch 1320/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7428536320.0000 - val_loss: 8261185536.0000\n",
      "Epoch 1321/1500\n",
      "119/119 [==============================] - 0s 944us/step - loss: 7408278016.0000 - val_loss: 8368733696.0000\n",
      "Epoch 1322/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7796214784.0000 - val_loss: 8159632384.0000\n",
      "Epoch 1323/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7444556800.0000 - val_loss: 8349278208.0000\n",
      "Epoch 1324/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7417147904.0000 - val_loss: 8194892800.0000\n",
      "Epoch 1325/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7538022912.0000 - val_loss: 8664361984.0000\n",
      "Epoch 1326/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7447770112.0000 - val_loss: 9075840000.0000\n",
      "Epoch 1327/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7648931840.0000 - val_loss: 8342262784.0000\n",
      "Epoch 1328/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7440120320.0000 - val_loss: 8205837824.0000\n",
      "Epoch 1329/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7384335872.0000 - val_loss: 8302550528.0000\n",
      "Epoch 1330/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7463546880.0000 - val_loss: 8539254272.0000\n",
      "Epoch 1331/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7495742976.0000 - val_loss: 8187464704.0000\n",
      "Epoch 1332/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7496648704.0000 - val_loss: 8837843968.0000\n",
      "Epoch 1333/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7496110592.0000 - val_loss: 8622849024.0000\n",
      "Epoch 1334/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7577104896.0000 - val_loss: 9528922112.0000\n",
      "Epoch 1335/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7802384384.0000 - val_loss: 8215414784.0000\n",
      "Epoch 1336/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7423173120.0000 - val_loss: 8300148736.0000\n",
      "Epoch 1337/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7541049344.0000 - val_loss: 10508122112.0000\n",
      "Epoch 1338/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7668140032.0000 - val_loss: 8340275200.0000\n",
      "Epoch 1339/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7623827968.0000 - val_loss: 8913977344.0000\n",
      "Epoch 1340/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7777217536.0000 - val_loss: 9474930688.0000\n",
      "Epoch 1341/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7432121344.0000 - val_loss: 8400274944.0000\n",
      "Epoch 1342/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7427366912.0000 - val_loss: 8178188800.0000\n",
      "Epoch 1343/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7354661888.0000 - val_loss: 8482169856.0000\n",
      "Epoch 1344/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7357067264.0000 - val_loss: 8114298880.0000\n",
      "Epoch 1345/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7324659200.0000 - val_loss: 8352161280.0000\n",
      "Epoch 1346/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7524596736.0000 - val_loss: 8265463808.0000\n",
      "Epoch 1347/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7703387136.0000 - val_loss: 8617205760.0000\n",
      "Epoch 1348/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7377823744.0000 - val_loss: 8166648320.0000\n",
      "Epoch 1349/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7399835648.0000 - val_loss: 8245937152.0000\n",
      "Epoch 1350/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7451554816.0000 - val_loss: 10106473472.0000\n",
      "Epoch 1351/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7456793600.0000 - val_loss: 8269871616.0000\n",
      "Epoch 1352/1500\n",
      "119/119 [==============================] - 0s 903us/step - loss: 7383020032.0000 - val_loss: 8307963904.0000\n",
      "Epoch 1353/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7807829504.0000 - val_loss: 8563607552.0000\n",
      "Epoch 1354/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7444138496.0000 - val_loss: 8181677568.0000\n",
      "Epoch 1355/1500\n",
      "119/119 [==============================] - 0s 930us/step - loss: 7554430464.0000 - val_loss: 8134708224.0000\n",
      "Epoch 1356/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7418046976.0000 - val_loss: 8174217216.0000\n",
      "Epoch 1357/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7457322496.0000 - val_loss: 8730175488.0000\n",
      "Epoch 1358/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7392437760.0000 - val_loss: 8174367744.0000\n",
      "Epoch 1359/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7320586240.0000 - val_loss: 8242311168.0000\n",
      "Epoch 1360/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7520654848.0000 - val_loss: 8527219200.0000\n",
      "Epoch 1361/1500\n",
      "119/119 [==============================] - 0s 919us/step - loss: 7457356800.0000 - val_loss: 8145430016.0000\n",
      "Epoch 1362/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7448798208.0000 - val_loss: 8212664832.0000\n",
      "Epoch 1363/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7360379392.0000 - val_loss: 8204863488.0000\n",
      "Epoch 1364/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7646376960.0000 - val_loss: 10085394432.0000\n",
      "Epoch 1365/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7627781120.0000 - val_loss: 8294098944.0000\n",
      "Epoch 1366/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7453604864.0000 - val_loss: 8155788288.0000\n",
      "Epoch 1367/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7369243136.0000 - val_loss: 8372042752.0000\n",
      "Epoch 1368/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7517324800.0000 - val_loss: 8451121152.0000\n",
      "Epoch 1369/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7592798208.0000 - val_loss: 8465249280.0000\n",
      "Epoch 1370/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7595742720.0000 - val_loss: 8574961152.0000\n",
      "Epoch 1371/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7597630976.0000 - val_loss: 8327604736.0000\n",
      "Epoch 1372/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7365417984.0000 - val_loss: 8169247744.0000\n",
      "Epoch 1373/1500\n",
      "119/119 [==============================] - 0s 900us/step - loss: 7423047680.0000 - val_loss: 8218941440.0000\n",
      "Epoch 1374/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7533849600.0000 - val_loss: 8408171520.0000\n",
      "Epoch 1375/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7343622144.0000 - val_loss: 8232337920.0000\n",
      "Epoch 1376/1500\n",
      "119/119 [==============================] - 0s 923us/step - loss: 7360675840.0000 - val_loss: 8482727936.0000\n",
      "Epoch 1377/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7465051136.0000 - val_loss: 8320673280.0000\n",
      "Epoch 1378/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7460449792.0000 - val_loss: 9199403008.0000\n",
      "Epoch 1379/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7640969216.0000 - val_loss: 8133099008.0000\n",
      "Epoch 1380/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7334457856.0000 - val_loss: 8428604928.0000\n",
      "Epoch 1381/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7585282560.0000 - val_loss: 8376480768.0000\n",
      "Epoch 1382/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7701041664.0000 - val_loss: 8176082944.0000\n",
      "Epoch 1383/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7334738944.0000 - val_loss: 8329345024.0000\n",
      "Epoch 1384/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7386044416.0000 - val_loss: 8121114624.0000\n",
      "Epoch 1385/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7408924672.0000 - val_loss: 8267634688.0000\n",
      "Epoch 1386/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7335850496.0000 - val_loss: 8169994752.0000\n",
      "Epoch 1387/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7466806784.0000 - val_loss: 8491231232.0000\n",
      "Epoch 1388/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7576847872.0000 - val_loss: 8217412096.0000\n",
      "Epoch 1389/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7480039424.0000 - val_loss: 8760261632.0000\n",
      "Epoch 1390/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7703710208.0000 - val_loss: 8168686080.0000\n",
      "Epoch 1391/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 7445912576.0000 - val_loss: 8117045248.0000\n",
      "Epoch 1392/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7679221248.0000 - val_loss: 8187844608.0000\n",
      "Epoch 1393/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7315779584.0000 - val_loss: 8172363264.0000\n",
      "Epoch 1394/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7423944192.0000 - val_loss: 8187664384.0000\n",
      "Epoch 1395/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7291898880.0000 - val_loss: 8128706048.0000\n",
      "Epoch 1396/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7470550528.0000 - val_loss: 8234029056.0000\n",
      "Epoch 1397/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7292674048.0000 - val_loss: 8345498112.0000\n",
      "Epoch 1398/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7416965632.0000 - val_loss: 8223646208.0000\n",
      "Epoch 1399/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7579796992.0000 - val_loss: 8151385088.0000\n",
      "Epoch 1400/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7621472768.0000 - val_loss: 8218148352.0000\n",
      "Epoch 1401/1500\n",
      "119/119 [==============================] - 0s 958us/step - loss: 7501872128.0000 - val_loss: 8234723328.0000\n",
      "Epoch 1402/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7378124800.0000 - val_loss: 8154927104.0000\n",
      "Epoch 1403/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7425252352.0000 - val_loss: 8239812608.0000\n",
      "Epoch 1404/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7557903360.0000 - val_loss: 8421069312.0000\n",
      "Epoch 1405/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7390479872.0000 - val_loss: 8253361664.0000\n",
      "Epoch 1406/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7575760896.0000 - val_loss: 8229688320.0000\n",
      "Epoch 1407/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7296114176.0000 - val_loss: 8620744704.0000\n",
      "Epoch 1408/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7416865792.0000 - val_loss: 8095213056.0000\n",
      "Epoch 1409/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7419502592.0000 - val_loss: 8146887168.0000\n",
      "Epoch 1410/1500\n",
      "119/119 [==============================] - 0s 949us/step - loss: 7588131328.0000 - val_loss: 9586802688.0000\n",
      "Epoch 1411/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7407406080.0000 - val_loss: 8197550080.0000\n",
      "Epoch 1412/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7376796672.0000 - val_loss: 8177170944.0000\n",
      "Epoch 1413/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7801067008.0000 - val_loss: 8565900288.0000\n",
      "Epoch 1414/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7528628736.0000 - val_loss: 8204742656.0000\n",
      "Epoch 1415/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7332904448.0000 - val_loss: 9040462848.0000\n",
      "Epoch 1416/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7512627712.0000 - val_loss: 8724352000.0000\n",
      "Epoch 1417/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7522080256.0000 - val_loss: 8771476480.0000\n",
      "Epoch 1418/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7733549056.0000 - val_loss: 8187712512.0000\n",
      "Epoch 1419/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7475419136.0000 - val_loss: 8380662272.0000\n",
      "Epoch 1420/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7372621312.0000 - val_loss: 8232453632.0000\n",
      "Epoch 1421/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7313067008.0000 - val_loss: 8182275584.0000\n",
      "Epoch 1422/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7489349120.0000 - val_loss: 8166055936.0000\n",
      "Epoch 1423/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7395423744.0000 - val_loss: 8237944320.0000\n",
      "Epoch 1424/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7384621568.0000 - val_loss: 8127789568.0000\n",
      "Epoch 1425/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7393089536.0000 - val_loss: 8244661760.0000\n",
      "Epoch 1426/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7379482624.0000 - val_loss: 8550859776.0000\n",
      "Epoch 1427/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7343015936.0000 - val_loss: 8294251520.0000\n",
      "Epoch 1428/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7312775168.0000 - val_loss: 8252023296.0000\n",
      "Epoch 1429/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7355401216.0000 - val_loss: 8109729280.0000\n",
      "Epoch 1430/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7709821952.0000 - val_loss: 8144737792.0000\n",
      "Epoch 1431/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7482068480.0000 - val_loss: 8430901248.0000\n",
      "Epoch 1432/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7328349696.0000 - val_loss: 8574619136.0000\n",
      "Epoch 1433/1500\n",
      "119/119 [==============================] - 0s 941us/step - loss: 7578459136.0000 - val_loss: 8452165120.0000\n",
      "Epoch 1434/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7588927488.0000 - val_loss: 8125824000.0000\n",
      "Epoch 1435/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7433430528.0000 - val_loss: 8289205248.0000\n",
      "Epoch 1436/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7301975552.0000 - val_loss: 8248195584.0000\n",
      "Epoch 1437/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7391577088.0000 - val_loss: 8133784064.0000\n",
      "Epoch 1438/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7471661056.0000 - val_loss: 8454585344.0000\n",
      "Epoch 1439/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7408235520.0000 - val_loss: 8551872000.0000\n",
      "Epoch 1440/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7386210816.0000 - val_loss: 8263969792.0000\n",
      "Epoch 1441/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7378720256.0000 - val_loss: 8177393152.0000\n",
      "Epoch 1442/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7387816960.0000 - val_loss: 8831655936.0000\n",
      "Epoch 1443/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7548314624.0000 - val_loss: 8580676608.0000\n",
      "Epoch 1444/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 890us/step - loss: 7557399040.0000 - val_loss: 8927130624.0000\n",
      "Epoch 1445/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7393496576.0000 - val_loss: 8174564864.0000\n",
      "Epoch 1446/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7547976192.0000 - val_loss: 8304657920.0000\n",
      "Epoch 1447/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7407886336.0000 - val_loss: 9181953024.0000\n",
      "Epoch 1448/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7583733760.0000 - val_loss: 8118028800.0000\n",
      "Epoch 1449/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7403977216.0000 - val_loss: 8298650112.0000\n",
      "Epoch 1450/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7496438272.0000 - val_loss: 8095347200.0000\n",
      "Epoch 1451/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7468186624.0000 - val_loss: 8150701568.0000\n",
      "Epoch 1452/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7890570240.0000 - val_loss: 8153952256.0000\n",
      "Epoch 1453/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7320985600.0000 - val_loss: 8289027584.0000\n",
      "Epoch 1454/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7378678784.0000 - val_loss: 8173531648.0000\n",
      "Epoch 1455/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7338405888.0000 - val_loss: 8302042624.0000\n",
      "Epoch 1456/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7718790656.0000 - val_loss: 9633078272.0000\n",
      "Epoch 1457/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7335024640.0000 - val_loss: 8133049856.0000\n",
      "Epoch 1458/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7767997440.0000 - val_loss: 8203324928.0000\n",
      "Epoch 1459/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7345250304.0000 - val_loss: 8170584064.0000\n",
      "Epoch 1460/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7457549824.0000 - val_loss: 8859612160.0000\n",
      "Epoch 1461/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7482824192.0000 - val_loss: 8577218048.0000\n",
      "Epoch 1462/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7339449856.0000 - val_loss: 8292557824.0000\n",
      "Epoch 1463/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7508882432.0000 - val_loss: 8151068160.0000\n",
      "Epoch 1464/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7838129152.0000 - val_loss: 8347020288.0000\n",
      "Epoch 1465/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7600006656.0000 - val_loss: 8103081984.0000\n",
      "Epoch 1466/1500\n",
      "119/119 [==============================] - 0s 878us/step - loss: 7376097280.0000 - val_loss: 8438518272.0000\n",
      "Epoch 1467/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7413692928.0000 - val_loss: 8131822592.0000\n",
      "Epoch 1468/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7552493568.0000 - val_loss: 8120823296.0000\n",
      "Epoch 1469/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7284337152.0000 - val_loss: 8163814400.0000\n",
      "Epoch 1470/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7351704064.0000 - val_loss: 8122669568.0000\n",
      "Epoch 1471/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7501222912.0000 - val_loss: 9056018432.0000\n",
      "Epoch 1472/1500\n",
      "119/119 [==============================] - 0s 873us/step - loss: 7589575680.0000 - val_loss: 9552606208.0000\n",
      "Epoch 1473/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7573033984.0000 - val_loss: 8591405056.0000\n",
      "Epoch 1474/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7553102848.0000 - val_loss: 8093998592.0000\n",
      "Epoch 1475/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7475111936.0000 - val_loss: 8438337024.0000\n",
      "Epoch 1476/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7409076736.0000 - val_loss: 9132205056.0000\n",
      "Epoch 1477/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7475488256.0000 - val_loss: 8117266944.0000\n",
      "Epoch 1478/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7462379008.0000 - val_loss: 8399388672.0000\n",
      "Epoch 1479/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7464479232.0000 - val_loss: 8110846976.0000\n",
      "Epoch 1480/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7421624832.0000 - val_loss: 8352363008.0000\n",
      "Epoch 1481/1500\n",
      "119/119 [==============================] - 0s 898us/step - loss: 7547207168.0000 - val_loss: 8148452864.0000\n",
      "Epoch 1482/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7413336576.0000 - val_loss: 8109025280.0000\n",
      "Epoch 1483/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7322142720.0000 - val_loss: 8308657152.0000\n",
      "Epoch 1484/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7387776000.0000 - val_loss: 8331593728.0000\n",
      "Epoch 1485/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7234161664.0000 - val_loss: 8458916352.0000\n",
      "Epoch 1486/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7378470912.0000 - val_loss: 8113948160.0000\n",
      "Epoch 1487/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7434077696.0000 - val_loss: 8105297920.0000\n",
      "Epoch 1488/1500\n",
      "119/119 [==============================] - 0s 882us/step - loss: 7398896640.0000 - val_loss: 8272559104.0000\n",
      "Epoch 1489/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7555603968.0000 - val_loss: 8147261952.0000\n",
      "Epoch 1490/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7416914432.0000 - val_loss: 8133621248.0000\n",
      "Epoch 1491/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7634885632.0000 - val_loss: 8514982400.0000\n",
      "Epoch 1492/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7326228480.0000 - val_loss: 8104941568.0000\n",
      "Epoch 1493/1500\n",
      "119/119 [==============================] - 0s 890us/step - loss: 7507854848.0000 - val_loss: 8457559040.0000\n",
      "Epoch 1494/1500\n",
      "119/119 [==============================] - 0s 907us/step - loss: 7378778112.0000 - val_loss: 8113378304.0000\n",
      "Epoch 1495/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7417807360.0000 - val_loss: 8726112256.0000\n",
      "Epoch 1496/1500\n",
      "119/119 [==============================] - 0s 899us/step - loss: 7273679360.0000 - val_loss: 8550659072.0000\n",
      "Epoch 1497/1500\n",
      "119/119 [==============================] - 0s 924us/step - loss: 7547028992.0000 - val_loss: 9318978560.0000\n",
      "Epoch 1498/1500\n",
      "119/119 [==============================] - 0s 922us/step - loss: 7584477184.0000 - val_loss: 8158880768.0000\n",
      "Epoch 1499/1500\n",
      "119/119 [==============================] - 0s 915us/step - loss: 7351410176.0000 - val_loss: 8724425728.0000\n",
      "Epoch 1500/1500\n",
      "119/119 [==============================] - 0s 932us/step - loss: 7298454528.0000 - val_loss: 8152611328.0000\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 19)                1558      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 3,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=128,epochs=1500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02efeb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe89dde3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d70d6e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 0s 436us/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "126706f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da2dba08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8206481218728356"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b78e3f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85861.12550553904"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5519932",
   "metadata": {},
   "source": [
    "### Deep Learning - MNIST Data Set - 60 bin el yazmasi rakam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1edf07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeni dosyada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
